---
format:
  revealjs:
    theme: [serif, slides.scss]
    # embed-resources: true
author: "Jon Reades"
title: "Assessments"
footer: "Assessments • Jon Reades"
highlight-style: github
code-copy: true
code-line-numbers: true
slide-level: 2
title-slide-attributes:
  data-background-image: ../img/CASA_Logo_no_text.png
  data-background-size: cover
  data-background-position: center
  data-background-opacity: '0.17'
logo: img/CASA_logo.png
history: false
css: slides.css
---

## Organise (Your Group)

I am working to allocate everyone to a group of at least four so:

- If you are in a group of less than four you *may* be partnered with students in another practical session to make a 'full strength' group. 
- In this case, you will be reallocated to a mutually convenient practical session so that you are not penalised by being unable to work together.
- I would encourage you to start sitting and working together, and for *one* of you to set up and share a private GitHub repo for Assessment #2 (more on this in a second).

And **remember**: *talk* about how you want your group to work! See: [Group Working](https://jreades.github.io/fsds/sessions/week1.html#class) talk.^[*Note*: In my experience overly narrow specialisation does not work.]

## Assessment #1

#### 1. What is it?

Timed, Open Book Exam

#### 2. What does 'timed' mean?

Once you start the assessment you will have a fixed amount of time in which to complete it; **2 hours** for most students, but students with relevant SORAs have **3 hours** (please email me).

#### Ok, so when is it?

**{{< var assess.quiz-date >}}**

#### What is the window?

**{{< var assess.quiz-time >}}**^[This is the 'window' for doing the assessment. You can start any time *after* the window opens but must finish *before* the window closes.]

---

#### How do I complete it?

You will access your questions **through Moodle**. You can write the code that you need to *answer* the question in JupyterLab or any other **Python programming environment**. 

#### What does 'open book' mean?

**You may *look*** at any resource you like, **you may not *ask*** another human being for assistance. **You *may* use ChatGPT or another LLM**.

#### What will the exam be on?

The focus will be on the effective use of `pandas` to process a small data set, but any concept *up to and including Week 5* is 'fair game'^[I will not ask about the use of Git/GitHub or Docker.]. The exam will consist of *no more* than 15 questions.^[So, roughly, that means about 8 minutes/question.] 

---

#### How does it work?

For each question, your answer will consist of: 

1. A *comment* containing your answer to the question; 
2. A *boolean* value (`True`/`False`) indicating whether you used a Large Language Modle (such as ChatGPT); and 
3. A *code block* containing the code that you used to obtain that answer.

For example: To two decimal places, what is the modal price and number of nights in the data set?

{{< include ../assessments/_exam_example.qmd >}}

---

#### 8. How is it graded?

I will be running the code that you pasted into your answer and comparing it to: 

1. The answers that you have *provided* in the comment; 
2. The answer that was *expected* for the data.

The use of ChatGPT has no impact on your grade, I am primarily curious about how useful people are finding it and whether LLMs affect your understanding of coding questions.

## Assessment #2

The reproducible analysis *must* be a runnable QMD (Quarto Markdown Document) file that addresses the set questions provided in class. The QMD file will be assessed on two components:

1. Its **content** (60% of this assessment): do the answers written by the group engage through a mix of literature, critical thinking, and data analysis with the set questions?
2. Its **reproducibility** (40% of this assessment): do the analyses employed, and outputs created by the group run fully and without errors on a different computer, and do they show evidence of thought in relation to the quality of coding and outputs?

A [template](https://github.com/jreades/fsds/blob/master/assessments/Group_Work.qmd) has been provided. You can see both [PDF](https://jreades.github.io/fsds/assessments/Group_Work.pdf) and [HTML](https://jreades.github.io/fsds/assessments/Group_Work.html) output, but please *only* submit the PDF!

---

### Part 1: Set Questions (60%)

Starting in Week 7, groups will be randomly selected to present their answer to *one* of that week's question *in class*. 

- Formative feedback will be provided *in class* on the quality of the response.
- If the selected group has not prepared an answer then no formative feedback will be provided for that question.

The format is *not* academic: while referencing is still expected, the style for all questions should be written for a *non-specialist* audience. I am updating the rubric to clarify this.

---

### Part 2: Reproducibility (40%)

Your QMD document will be evaluated *separately* from its content for:

1. *Reproducibility* (20%) — Can the analysis be run on another system? Two considerations: 1) without changes to the code; and 2) with useful guidance/documentation being offered in terms of what to do if ‘things go wrong’.
2. *Quality* (20%) — Is the code/analysis intelligible and well-presented such that another user doesn’t just ‘run the code’ but actually understands and has confidence in the how and why of what you've done? This is about making maximal use of the tools at their disposal such that the code is efficient, even elegant, and the outputs are clear and legible.

## Assessment #3

We know that people contribute differently to groups or, sometimes, not at all. This self- and peer-assessment seeks to quantify that contribution while also prompting you to reflect on what *you* contributed to your group. This assessment also has two components:

1. A free-text *self*-assessment: this component is *formative* but may be used to moderate the summative component in the event of a complaint or disagreement.
2. A Likert-scale (1–6) *peer*-assessment: this component is *summative* and you will be asked to rank other members of the group on their contribution to the group project together with a short free-text justification of that score. The free-text feedback will not be shared with the other group members, but may be used to moderate the summative component in the event of a compalint or disagreement.


---

### Part 1: Self-Assessment

The questions are detailed [here](../assessments/peer.html), but for the avoidance of doubt.

{{< include ../assessments/_self.qmd >}}

---

### Part 2: Peer-Assessment

For each member of the group, not including yourself, you are asked to reflect on the following prompt before assigning a score on a scale of 1 (did not contribute) to 6 (was an outstanding contributor):

{{< include ../assessments/_peer.qmd >}}
