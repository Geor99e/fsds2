{
  "hash": "d2bec8986e07675f2c970a183c2c526c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Practical 5: Pandas\"\nsubtitle: \"Easing into EDA\"\njupyter: python3\nfilters:\n  - qna\n  - quarto\n---\n\n\n| Complete | Part 1: Foundations | Part 2: Data | Part 3: Analysis |     |\n| :------- | :------------------ | :----------- | :--------------- | --: |\n| 40% | &#9619;&#9619;&#9619;&#9619;&#9619;&#9619;&#9619;&#9619; | &#9619;&#9617;&#9617;&#9617;&#9617;&#9617; | &#9617;&#9617;&#9617;&#9617;&#9617;&#9617; | 5/10\n\n<style type=\"text/css\">\n.longform {\n    max-height: 300px;\n    overflow-y: scroll;\n}\n</style>\n\nThis session is a tour-de-`pandas`; since this is Python's equivalent of the `tidyverse` meets `data.tables` it is fundamental to the data science ecosystem and is probably one of the most-widely used libraries in the language as a whole. I get [more than 285,000 questions](https://stackoverflow.com/questions/tagged/pandas) tagged with pandas on StackOverflow. \n\nThis week we are also going to start looking at the **[InsideAirbnb](http://insideairbnb.com/)** data which forms the core of the work that we do over the rest of the term. The focus of *this* notebook is simple numeric data: no mapping or text data... yet... and direct manipulation of data types, derivation of summary statistics, and simple plotting.\n\nWe hope that you will be able to draw on the past few practical sessions to develop a more intuitive understanding of how to interact with pandas since it supports both a 'dictionary-of-lists' style of interaction *and* a methods-based style of interaction with the 'Data Frame'.\n\n::: {.callout-warning}\n\n### Important\n\nConceptually, this practical links together _all_ of the preceding ones; you will find data structures, classes and methods, reading CSV files from a remote location, `numpy`, and more than you ever wanted to know about data types in Python. Making these connections will make the remainder of term much, much easier, so it might be worth **revising this practical** over Reading Week so make sure it all makes sense!\n\n:::\n\n# The Importance of EDA\n\nAfter a few weeks getting to grips with Python, we're now going to start working with some real data. One of the first things that we do when working with any new data set is to familiarise ourselves with it. There are a _huge_ number of ways to do this, but there are no shortcuts to:\n\n1. Reading about the data (how it was collected, what the sample size was, etc.)\n2. Reviewing any accompanying metadata (data about the data, column specs, etc.)\n3. Looking at the data itself at the row- and column-levels\n4. Producing descriptive statistics\n5. Visualising the data using plots\n\nYou should use _all_ of these together to really understand where the data came from, how it was handled, and whether there are gaps or other problems. If you're wondering which comes first, the concept of _start with a chart_ is always good... though we've obviously not _quite_ gotten there yet! This week we want you to get a handle on pandas itself, so although we will do some plotting of charts, we'll focus on 3-4 with a tiny bit of 5. There will be much more on plotting charts next week, and you should be looking into 1 and 2 yourself based on what's been written both on the [Inside Airbnb web site](http://insideairbnb.com/about.html) and in the [suggested readings](https://github.com/jreades/i2p/blob/master/ref/Bibliography.md).\n\nSo although they don't need to be done now, you probably want to add both those links to your reading list!\n\n# Preamble\n\n::: {.callout-note}\n\n#### &#128279; Connections\n\nThis is why we spent time talking about [Packages](https://jreades.github.io/fsds/sessions/week3.html#lectures), [Methods](https://jreades.github.io/fsds/sessions/week4.html#lectures) [Classes](https://jreades.github.io/fsds/sessions/week4.html#lectures) in the lectures... because now we're going to be making _intensive_ use of them.\n\n:::\n\nIt's always sensible to import packages these at the top of the notebook:\n\n1. Because it lets everyone know what they need to have installed to run your code.\n2. It's easy to run this and then skip further down the notebook if you have already done *some* of the work and saved an intermediate output.\n\n::: {#4218947e .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport numpy as np\nimport pandas as pd\n```\n:::\n\n\nBeyond what we provide below there are [numerous](http://lmgtfy.com/?q=introduction+to+pandas+python) useful introductions; [one of our favourites](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/) is from Greg Reda, and there are some [good videos](https://youtu.be/TSsSWuhBpmY) on [our YouTube channel](https://www.youtube.com/playlist?list=PLJ5Y5hxm-0W7rOOYBHf6KC6QNnWOi09kh). And of course, thereâ€™s [TONS of stuff](http://stackoverflow.com/questions/tagged/pandas) on StackOverflow. If you want an actual physical book, you might try [McKinney (2017)](http://shop.oreilly.com/product/0636920050896.do).\n\nHowever, one thing you will really want to bookmark is [the official documentation](http://pandas.pydata.org/pandas-docs/stable/) since you will undoubtedly need to refer to it fairly regularly. _Note_: this link is to the most recent release. Over time there will be updates published and you _may_ find that you no longer have the most up-to-date version. If you find that you are now using an older version of pandas and the methods have changed then you'll need to track down the _specific_ version of the documentation that you need from the [home page](http://pandas.pydata.org).\n\nYou can always check what version you have installed like this:\n\n::: {#81f4529d .cell execution_count=2}\n``` {.python .cell-code}\nprint(pd.__version__)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.2.2\n```\n:::\n:::\n\n\n::: {.callout-tip}\n\nThe `<package_name>.__version__` approach isn't guaranteed to work with _every_ package, but it will work with most of them. Remember that variables and methods starting and ending with '`__`' are **private** and any interaction with them should be approached very, very carefully.\n\n:::\n\n# Reading and Writing Data\n\n::: {.callout-note}\n\n#### &#128279; Connections\n\nYou will _really_ need to get to grips with Pandas through the lectures on [Data](https://jreades.github.io/fsds/sessions/week5.html#lectures) and [Pandas](https://jreades.github.io/fsds/sessions/week5.html#lectures).\n\n:::\n\nPandas can do a *lot*, and you might be feeling a little intimidated by this, but here's the thing: we were already writing something like pandas from scratch! That's because pandas takes a **column-view of data** in the same way that our **Dictionary-of-Lists** did, it's just that it's got a lot more features than our 'simple' tool did. That's why the documentation is so much more forbidding and why pandas is so much more powerful.\n\nBut at its heart, a pandas `Data Frame` (`df` for short) is a collection of `Data Series` objects (i.e. columns) with an index. Each Series is like one of our column-lists from the last notebook. And the `df` is like the dictionary that held the data together. So you've seen this before and you already _know_ what's going on... or at least you now have an _analogy_ that you can use to make sense of pandas:\n\n```python\nmyDataFrame = {\n    '<column_name_1>': <Series_1>,\n    '<column_name_2>': <Series_2>,\n    '<column_name_3>': <Series_3>\n}\n``` \n\nAnd pandas gives us two ways to access that data:\n\n1. Using a method syntax: `myDataFrame.column_name_1`\n2. Using a dictionary syntax: `myDataFrame['column_name_1']`\n\nDepending on which syntax you prefer, you can use these interchangeably. The only times you *have* to choose one over the other are: \n\n- Assignment (e.g. `myDataFrame['column_name_1'] = ...`); \n- Columns with spaces in their names (e.g. `myDataFrame['Column Name 1')`).\n\n## Reading Remote Data\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low (this time around).\n\n:::\n\nYou will need to do several things here to read the remote, compressed CSV file specified by `url` into a data frame called `df`. Setting `low_memory=False` ensures that pandas will try to load the entire data set _before_ guessing the data format! Obviously, with very large files this is probably a bad idea and it's possible to force a particular column type while readng in the data as well. For larger data sets there are platforms like [Dask](https://dask.org/) (see, eg, [this](https://towardsdatascience.com/why-and-how-to-use-dask-with-big-data-746e34dac7c3)), and beyond that are [other options](https://towardsdatascience.com/scaling-pandas-comparing-dask-ray-modin-vaex-and-rapids-c74c85a4e59c).\n\n:::: {.qna}\n\n#### Question\n\n```python\n# Set download URL\nymd  = '{{< var data.ymd >}}'\nhost = 'https://orca.casa.ucl.ac.uk'\nurl  = f'{host}/~jreades/data/{ymd}-listings.csv.gz'\n\n# your code here\ndf = pd.read_csv(??, compression='gzip', low_memory=False)\nprint(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")\n```\n\n#### Answer\n\nThis is a bit of a fuller answer than the question, but hopefully you'll see why we take this approach as a 'better' one that the skeleton set out in the Question. Note that you can also find reviews and calendar at the same location as the listings file (i.e. `{{< var data.ymd >}}-calendar.csv.gz`)\n\n::: {#2a360c24 .cell execution_count=3}\n``` {.python .cell-code}\n# Notice that we import a specific error here\n# but other types of errors (e.g. NameError)\n# are always available because they're so basic.\nfrom urllib.error import URLError\n\n# Set download URL\nymd  = '2023-09-06'\nhost = 'https://orca.casa.ucl.ac.uk'\nurl  = f'{host}/~jreades/data/{ymd}-listings.csv.gz'\n\nif not os.path.exists('tmp.csv.gz'):\n    print(\"Didn't find tmp.csv.gz locally\")\n    try:\n        df = pd.read_csv(url, compression='gzip', low_memory=False)\n        df.to_csv('tmp.csv.gz', compression='gzip', index=False)\n    except URLError as e:\n        print(f\"Unable to access: {url}\")\n        print(e)\nelse:\n    print(\"Found tmp.csv.gz locally\")\n    df = pd.read_csv('tmp.csv.gz', compression='gzip', low_memory=False)\n\ntry:\n    print(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")\nexcept NameError as e:\n    print(\"Unable to load the data\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound tmp.csv.gz locally\nData frame is 87,953 x 75\n```\n:::\n:::\n\n\n::::\n\nYou should get a data frame containing 75 columns and 87\\,953 rows of data.\n\n## Inspecting the Data Frame\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low.\n\n:::\n\nLet's get a general sense of the data by printing out information _about_ the data frame. There are several ways to do this (and we'll see another futher on):\n\n- `df.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)` -- descriptive stats for all **numeric** columns\n- `df.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None)` -- summarises all columns, but without distribution information\n- `df.memory_usage(index=True, deep=True)` -- memory usage details about each column (can be quite slow as it's doing a *lot* of digging)\n\n:::: {.qna}\n\n#### Question\n\nWhat is another term for the 0.5 percentile?\n\n#### Answer\n\nThe median!\n\n::::\n\n### Describing\n\n\n\nDescribing a data frame provides general information about *numeric* columns, such as the median, IQR, or number of discrete values. \n\nSo to show the 5th and 95th percentiles you need to pass an argument to `describe` to override the default report from pandas:\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf.describe(percentiles=[??])\n```\n\n#### Answer\n\n::: {#a7f92cd1 .cell execution_count=5}\n``` {.python .cell-code}\ndf.describe(percentiles=[.05,0.95]) # 0.5 is always shown\n```\n\n::: {.cell-output .cell-output-display execution_count=84}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>host_id</th>\n      <th>host_total_listings_count</th>\n      <th>neighbourhood_group_cleansed</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>accommodates</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>beds</th>\n      <th>...</th>\n      <th>review_scores_cleanliness</th>\n      <th>review_scores_checkin</th>\n      <th>review_scores_communication</th>\n      <th>review_scores_location</th>\n      <th>review_scores_value</th>\n      <th>calculated_host_listings_count</th>\n      <th>calculated_host_listings_count_entire_homes</th>\n      <th>calculated_host_listings_count_private_rooms</th>\n      <th>calculated_host_listings_count_shared_rooms</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8.794600e+04</td>\n      <td>8.795300e+04</td>\n      <td>87941.000000</td>\n      <td>7.000000</td>\n      <td>87946.000000</td>\n      <td>87946.000000</td>\n      <td>87946.000000</td>\n      <td>0.0</td>\n      <td>55172.00000</td>\n      <td>86812.000000</td>\n      <td>...</td>\n      <td>64859.000000</td>\n      <td>64815.000000</td>\n      <td>64845.000000</td>\n      <td>64815.000000</td>\n      <td>64814.000000</td>\n      <td>87939.000000</td>\n      <td>87939.000000</td>\n      <td>87939.000000</td>\n      <td>87939.000000</td>\n      <td>65782.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.586523e+17</td>\n      <td>1.589778e+08</td>\n      <td>85.809725</td>\n      <td>7.714286</td>\n      <td>51.506070</td>\n      <td>-0.051592</td>\n      <td>3.241466</td>\n      <td>NaN</td>\n      <td>1.78674</td>\n      <td>1.806098</td>\n      <td>...</td>\n      <td>4.623342</td>\n      <td>4.777316</td>\n      <td>4.798883</td>\n      <td>4.720488</td>\n      <td>4.593429</td>\n      <td>18.142292</td>\n      <td>13.853285</td>\n      <td>4.133877</td>\n      <td>0.029157</td>\n      <td>1.014973</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.121119e+17</td>\n      <td>1.694025e+08</td>\n      <td>523.634401</td>\n      <td>12.065299</td>\n      <td>0.406154</td>\n      <td>8.910026</td>\n      <td>9.099381</td>\n      <td>NaN</td>\n      <td>1.12417</td>\n      <td>1.322378</td>\n      <td>...</td>\n      <td>0.551080</td>\n      <td>0.457758</td>\n      <td>0.451855</td>\n      <td>0.421899</td>\n      <td>0.536366</td>\n      <td>63.747634</td>\n      <td>46.878272</td>\n      <td>24.743680</td>\n      <td>0.490387</td>\n      <td>1.365493</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.391300e+04</td>\n      <td>1.000000e+00</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>-0.497800</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010000</td>\n    </tr>\n    <tr>\n      <th>5%</th>\n      <td>6.029746e+06</td>\n      <td>2.362913e+06</td>\n      <td>1.000000</td>\n      <td>2.300000</td>\n      <td>51.420350</td>\n      <td>-0.297219</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>3.670000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.730000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.020000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.935854e+07</td>\n      <td>8.133343e+07</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>51.513770</td>\n      <td>-0.126391</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>2.00000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>4.800000</td>\n      <td>4.940000</td>\n      <td>4.970000</td>\n      <td>4.840000</td>\n      <td>4.740000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.540000</td>\n    </tr>\n    <tr>\n      <th>95%</th>\n      <td>9.481452e+17</td>\n      <td>4.997364e+08</td>\n      <td>213.000000</td>\n      <td>26.000000</td>\n      <td>51.587750</td>\n      <td>0.028270</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>4.00000</td>\n      <td>4.000000</td>\n      <td>...</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>85.000000</td>\n      <td>73.000000</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>3.700000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.738958e+17</td>\n      <td>5.355140e+08</td>\n      <td>5272.000000</td>\n      <td>35.000000</td>\n      <td>51.681642</td>\n      <td>1125.000000</td>\n      <td>1125.000000</td>\n      <td>NaN</td>\n      <td>50.00000</td>\n      <td>59.000000</td>\n      <td>...</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>595.000000</td>\n      <td>312.000000</td>\n      <td>285.000000</td>\n      <td>18.000000</td>\n      <td>50.250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 35 columns</p>\n</div>\n```\n:::\n:::\n\n\n::::\n\n### Info\n\nThe `info` method provides a more system-oriented view of the data frame, helping you to understand what each column is composed of, how many NAs there might be, and some high-level (but often incomplete) data on performance.\n\n::: {.longform}\n\n::: {#65a96a51 .cell execution_count=6}\n``` {.python .cell-code}\ndf.info(verbose=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 87953 entries, 0 to 87952\nData columns (total 75 columns):\n #   Column                                        Non-Null Count  Dtype  \n---  ------                                        --------------  -----  \n 0   id                                            87946 non-null  float64\n 1   listing_url                                   87950 non-null  object \n 2   scrape_id                                     87950 non-null  object \n 3   last_scraped                                  87951 non-null  object \n 4   source                                        87953 non-null  object \n 5   name                                          87953 non-null  object \n 6   description                                   86686 non-null  object \n 7   neighborhood_overview                         47194 non-null  object \n 8   picture_url                                   87950 non-null  object \n 9   host_id                                       87953 non-null  float64\n 10  host_url                                      87953 non-null  object \n 11  host_name                                     87948 non-null  object \n 12  host_since                                    87948 non-null  object \n 13  host_location                                 69172 non-null  object \n 14  host_about                                    45913 non-null  object \n 15  host_response_time                            59024 non-null  object \n 16  host_response_rate                            59031 non-null  object \n 17  host_acceptance_rate                          62760 non-null  object \n 18  host_is_superhost                             87014 non-null  object \n 19  host_thumbnail_url                            87941 non-null  object \n 20  host_picture_url                              87941 non-null  object \n 21  host_neighbourhood                            48075 non-null  object \n 22  host_listings_count                           87941 non-null  object \n 23  host_total_listings_count                     87941 non-null  float64\n 24  host_verifications                            87941 non-null  object \n 25  host_has_profile_pic                          87941 non-null  object \n 26  host_identity_verified                        87941 non-null  object \n 27  neighbourhood                                 47194 non-null  object \n 28  neighbourhood_cleansed                        87946 non-null  object \n 29  neighbourhood_group_cleansed                  7 non-null      float64\n 30  latitude                                      87946 non-null  float64\n 31  longitude                                     87946 non-null  float64\n 32  property_type                                 87946 non-null  object \n 33  room_type                                     87946 non-null  object \n 34  accommodates                                  87946 non-null  float64\n 35  bathrooms                                     0 non-null      float64\n 36  bathrooms_text                                87843 non-null  object \n 37  bedrooms                                      55172 non-null  float64\n 38  beds                                          86812 non-null  float64\n 39  amenities                                     87946 non-null  object \n 40  price                                         87946 non-null  object \n 41  minimum_nights                                87946 non-null  object \n 42  maximum_nights                                87946 non-null  float64\n 43  minimum_minimum_nights                        87945 non-null  float64\n 44  maximum_minimum_nights                        87945 non-null  float64\n 45  minimum_maximum_nights                        87944 non-null  object \n 46  maximum_maximum_nights                        87944 non-null  object \n 47  minimum_nights_avg_ntm                        87944 non-null  float64\n 48  maximum_nights_avg_ntm                        87944 non-null  float64\n 49  calendar_updated                              6 non-null      float64\n 50  has_availability                              87945 non-null  object \n 51  availability_30                               87945 non-null  float64\n 52  availability_60                               87945 non-null  float64\n 53  availability_90                               87945 non-null  float64\n 54  availability_365                              87939 non-null  float64\n 55  calendar_last_scraped                         87946 non-null  object \n 56  number_of_reviews                             87946 non-null  float64\n 57  number_of_reviews_ltm                         87946 non-null  float64\n 58  number_of_reviews_l30d                        87946 non-null  float64\n 59  first_review                                  65789 non-null  object \n 60  last_review                                   65788 non-null  object \n 61  review_scores_rating                          65782 non-null  float64\n 62  review_scores_accuracy                        64847 non-null  float64\n 63  review_scores_cleanliness                     64859 non-null  float64\n 64  review_scores_checkin                         64815 non-null  float64\n 65  review_scores_communication                   64845 non-null  float64\n 66  review_scores_location                        64815 non-null  float64\n 67  review_scores_value                           64814 non-null  float64\n 68  license                                       1 non-null      object \n 69  instant_bookable                              87939 non-null  object \n 70  calculated_host_listings_count                87939 non-null  float64\n 71  calculated_host_listings_count_entire_homes   87939 non-null  float64\n 72  calculated_host_listings_count_private_rooms  87939 non-null  float64\n 73  calculated_host_listings_count_shared_rooms   87939 non-null  float64\n 74  reviews_per_month                             65782 non-null  float64\ndtypes: float64(35), object(40)\nmemory usage: 50.3+ MB\n```\n:::\n:::\n\n\n:::\n\nYou should get that the data frame has a mix of `float64`, `int`, and `object` (text) columns and that some columns contain many nulls. You will also get an *estimate* of memory usage that may differ substantially from the more complete picture provided below, which suggests a 'true' value of 396MB.\n\n### Memory Usage\n\nIf you really need to get into the 'weeds' and profile your data frame because you are crashing Python and seeing messages about 'core dumped', or seeing appallingly poor performance, then `memory_usage` is the way to go:\n\n```python\ndf.memory_usage(index=True, deep=True)\n```\n\n::: {.longform}\n\n::: {#d6467faf .cell execution_count=7}\n\n::: {.cell-output .cell-output-display execution_count=86}\n```\nIndex                                               132\nid                                               703624\nlisting_url                                     7940958\nscrape_id                                       5540904\nlast_scraped                                    5189137\n                                                 ...   \ncalculated_host_listings_count                   703624\ncalculated_host_listings_count_entire_homes      703624\ncalculated_host_listings_count_private_rooms     703624\ncalculated_host_listings_count_shared_rooms      703624\nreviews_per_month                                703624\nLength: 76, dtype: int64\n```\n:::\n:::\n\n\n:::\n\nYou should see that the data frame uses 415\\,086\\,430 bytes of memory, but the *really* important thing to note here is the difference between `string` and other types of data: keeping data as raw strings (instead of converting to categories, for instance) uses up a *lot* more memory and this can have a huge impact on the performance of your code.\n\n### Printing the Columns\n\nFinally, I find it *very* useful to be able to quickly print out a list of the **columns** without all of the details shown above. You just need to _print_ the _columns_ as a _list_:\n\n::: {#a2d76c1f .cell execution_count=8}\n``` {.python .cell-code}\nprint(df.columns.to_list())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name', 'description', 'neighborhood_overview', 'picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'license', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month']\n```\n:::\n:::\n\n\nYou should get a list showing every single column. If you get `Index(['id', 'listing_url',...], dtype='object')` then you have printed the column _index_ object and you to need to tell the object to convert its output **to a list** (*hint*: Google).\n\n## Saving the File Locally\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nNow save the file somewhere local so that you don't have to keep downloading 40MB of compressed data every time you want to start the practical. We'll be using this data for the rest of term, so you might as well save yourself some time and bandwidth! We'll talk more about data processing pipelines over the course of the term, but I'd suggest putting this data set into a `data/raw` folder because then you can have directories like `data/clean` and `data/analytical` as you move through the process of cleaning and prepping your data for analysis.\n\n::: {#32f4cedb .cell execution_count=9}\n``` {.python .cell-code}\npath = os.path.join('data','raw') # A default location to save raw data\nfn   = url.split('/')[-1]         # What does this do?\nprint(f\"Writing to: {fn}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWriting to: 2023-09-06-listings.csv.gz\n```\n:::\n:::\n\n\n::: {#25c929e0 .cell execution_count=10}\n``` {.python .cell-code}\nif not os.path.exists(path):      # And what does *this* do?\n    print(f\"Creating {path} under {os.getcwd()}\")\n    os.makedirs(path)\n\nif not os.path.exists(os.path.join(path,fn)):  \n    df.to_csv(os.path.join(path,fn), index=False)\n    print(\"Done.\")\n```\n:::\n\n\n# Managing Your Data\n\nWhen starting out it's common to think in terms of there being one input (the raw data) and one output (the results) to an analysis. In practice, you will have many intermediate outputs used as 'milestones' in the overall analysis: \n\n- You might have a 'canonical' data file that has dealt with formatting issues and converted the columns to appropriate data types.\n- You might have a 'clean' data file that has dealt with observations that seem to be incomplete or otherwise improperly formatted.\n- You might generate subsets by region or area.\n- You might produce an 'analytical' or 'final' data set appropriate to a specific analysis.\n\n**Most importantly**, if you are going to run the same analysis multiple times using data from different time periods (e.g. Land Registry's Price Paid Data is updated every month) then you will *multiple* versions of each of each of the above.\n\nBut, *in addition*, you might also be working with such a large data set that processing the *entire* thing every time you want to do some development work is impractical: do you want to load 1 billion rows only to find out that you needed 1,000 of them or that one of your columns is incorrectly formatted?\n\nSo although you _could_ do the next few steps as part of loading the _raw_ data, I always prefer to keep the original data set handy since I almost always discover that there are fields I didn't realise I needed when I started my work. \n\nSo my approach to coding is usually:\n\n1. Download the raw file and save it locally in a `data/raw` directory.\n2. Load the first `nrows` of data so that I can quickly:\n   - Check that the specification matches the data and select columns/rows accordingly.\n   - Identify obviously invalid rows/columns and investigate further.\n   - Check the code to fix data types and (where relevant) values works.\n   - Write this new, smaller file ($m` << m$ and $n` << n$) out to a `data/clean` or `data/canonical` directory (depending on whether formatting the columns is so complex or takes so long on a large data set that it needs to be separated out from actual cleaning).\n   - Test out some initial ideas for further analysis.\n3. Re-run the code (remove the `nrows` limit) using the full data set.\n\n::: {.callout-warning collapse=\"true\"}\n\n#### Difficulty: Moderate\n\nAlthough the code here is simple, the logic is not.\n\n::: \n\n## File Names\n\nYou should always be looking for ways to _avoid_ hard-coding values that might change over time, especially those linked to the date of the data file.\n\nIn this case you might try to work out how to make it easy to update the code to download the latest file. For instance, if the file looks like `2022-09-10-listings.csv.gz` then I might well specify the `url` as `{date}-listings.csv.gz` or `{year}-{month}-{day}-listings.csv.gz` and set up the variables that I need beforehand or in a separate file.\n\nUsing parameters makes it easier to write robust code that doesn't have unwanted side-effects. Here's a common one: you write code to download and process a file named `20221111-data.csv.gz`. After doing all the steps in Tasks 2 and 3 below you save it to `clean-data.csv.gz`. \n\n::: {.qna}\n\n#### Question\n\nWhat happens when your boss asks you to process `20221211-data.csv.gz`?\n\n#### Answer\n\nYou are going to lose every single output from the 2022-11-11 data that depends on `clean-data.csv.gz` because they are *all* going to now be generated from the 2022-12-11 data set instead. Worse, you will almost certainly have *no* way of knowing which output came from which data set (because you probably stopped tracking dates very early in your application).\n\n:::\n\n## File Loading\n\nNow let's write something that will allow us to more quickly write our code and validate the results in exploratory phase. For simplicity I've called this 'testing', but you could also think of it as 'dev' mode. What we want is to be able to easily swap between testing and operational contexts using a 'switch' (typically, a Boolean value) and limit the data load in testing mode.\n\nTo achieve this you could set pandas to:\n\n- Load only the first 10,000 rows using `nrows` *if* we are testing\n- Use the columns specified in `cols`\n- Allow pandas to load the entire data set before deciding on the column type by setting `low_memory` appropriately.\n\n### Row Subsetting\n\nLet's tackle the *rows* problem first:\n\n:::: {.qna}\n\n#### Question\n\n```python\ntesting = True\n\nif testing:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=??, ??)\nelse:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=??)\n\nprint(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")\n```\n\n#### Answer\n\n::: {#45999ceb .cell execution_count=11}\n``` {.python .cell-code}\ntesting = True\n\nif testing:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=False, nrows=10000)\nelse:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=False)\n\nprint(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData frame is 10,000 x 75\n```\n:::\n:::\n\n\n::::\n\nSo notice how this code deliberately works the same for either testing _or_ operational execution -- we just flip between the option by changing the `testing` variable from `True` to `False`! \n\nTo make this more robust and useful we could use this `testing` variable *throughout* our code if we wanted to change other behaviours based on development/deployment context. The state of the switch could then be set globally using an external configuration file (usually just called a 'conf file'). The easiest way to do this is to have a `conf.py` which contains your global parameters and then every script or notebook file reads in the configuration and sets these variables.\n\nSomething like:\n\n```python\ntesting = False\n```\n\nAnd:\n\n```python\nfrom conf import *\n```\n\n### Column Subsetting\n\nNow let's tackle the column problem... In order to avoid having to load lots of data that we aren't sure we need yet, we can restrict the columns that we load. We got `cols` below by copying the output of (`df.columns.to_list()` and then removing the fields that we thought we _weren't_ interested in.\n\n::: {#e8b9af86 .cell execution_count=12}\n``` {.python .cell-code}\ncols = ['id', 'listing_url', 'last_scraped', 'name', 'description', 'host_id', \n        'host_name', 'host_since', 'host_location', 'host_about', 'host_is_superhost', \n        'host_listings_count', 'host_total_listings_count', 'host_verifications', \n        'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', \n        'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', \n        'minimum_nights', 'maximum_nights', 'availability_365', 'number_of_reviews', \n        'first_review', 'last_review', 'review_scores_rating', 'license', \n        'reviews_per_month']\nprint(f\"Cols contains {len(cols)} columns.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCols contains 34 columns.\n```\n:::\n:::\n\n\nSo let's extend our previous answer\n\n:::: {.qna}\n\n#### Question\n\n```python\ntesting = True\n\nif testing:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=False, nrows=10000, ??)\nelse:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=False, ??)\n\nprint(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")\n```\n\n#### Answer\n\n::: {#d8a585b1 .cell execution_count=13}\n``` {.python .cell-code}\ntesting = True\n\nif testing:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=False, nrows=10000, usecols=cols)\nelse:\n    df = pd.read_csv(os.path.join(path,fn), \n                low_memory=False, usecols=cols)\n\nprint(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData frame is 10,000 x 34\n```\n:::\n:::\n\n\n::::\n\n## Releasing Memory\n\nA particular risk when working with Jupyter notebooks is that you either: a) have run code in an order *other* than the order shown in the notebook; or b) have made edits to code but *not* re-run the changed code. So you're still working from code that is no longer visible! \n\nWhen that happens you can get *very* confusing issues because what you *see* doesn't square with what the computer has *executed*. To resolve this without having to re-run the entire notebook (though that can *also* be a good choice!) you might want to 'delete' the current object and re-load or re-run the relevant data or code. \n\n::: {#23f459fa .cell execution_count=14}\n``` {.python .cell-code}\ndel(df)\n```\n:::\n\n\nSo we use `del(df)` to ensure that we aren't accidentally using the 'old' data frame. But another good reason to delete data you're no longer using is to free up memory.\n\n# Exploring Your Data\n\nLet's start over from the saved data:\n\n::: {#0114713c .cell execution_count=15}\n``` {.python .cell-code}\ndf = pd.read_csv(os.path.join(path,fn), \n                low_memory=False, usecols=cols)\n```\n:::\n\n\n## Selecting Rows \n\n::: {.callout-note}\n\n#### &#128279; Connections\n\nYou will want to refer to the [Randomness](https://jreades.github.io/fsds/sessions/week5.html#lectures) lecture to understand how we can select the _same_ random sample each time and to the session on [Logic](https://jreades.github.io/fsds/sessions/week5.html#lectures) lecture to cover `NaN`s and `NA`s.\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nI often like to start my EDA by simply printing out randomly-selected rows to get a feel for what's in the data. Does what I see square with what I read in the documentation? What does the `name` look like? What do I see in `last_scraped` and is it a sensible? What's the `id` field for?\n\n::: {#18243689 .cell execution_count=16}\n``` {.python .cell-code}\ndf.sample(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=95}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>description</th>\n      <th>host_id</th>\n      <th>host_name</th>\n      <th>host_since</th>\n      <th>host_location</th>\n      <th>host_about</th>\n      <th>...</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n      <th>maximum_nights</th>\n      <th>availability_365</th>\n      <th>number_of_reviews</th>\n      <th>first_review</th>\n      <th>last_review</th>\n      <th>review_scores_rating</th>\n      <th>license</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25490</th>\n      <td>25802906.0</td>\n      <td>https://www.airbnb.com/rooms/25802906</td>\n      <td>2023-09-06</td>\n      <td>Home in Greater London Â· â˜…5.0 Â· 3 bedrooms Â· 3...</td>\n      <td>Stay calm and relaxed in a comfortable modern ...</td>\n      <td>46564911.0</td>\n      <td>Roger</td>\n      <td>2015-10-14</td>\n      <td>London, United Kingdom</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>$99.00</td>\n      <td>6</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2018-06-14</td>\n      <td>2018-07-29</td>\n      <td>5.00</td>\n      <td>NaN</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>37886</th>\n      <td>40361254.0</td>\n      <td>https://www.airbnb.com/rooms/40361254</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· â˜…4.48 Â· 1 bedr...</td>\n      <td>Just a stone's throw from King's Cross St Panc...</td>\n      <td>259278549.0</td>\n      <td>Joe A Joseph</td>\n      <td>2019-05-01</td>\n      <td>London, United Kingdom</td>\n      <td>I love traveling. I love meeting and hosting p...</td>\n      <td>...</td>\n      <td>$152.00</td>\n      <td>1</td>\n      <td>1125.0</td>\n      <td>339.0</td>\n      <td>91.0</td>\n      <td>2019-12-21</td>\n      <td>2023-08-20</td>\n      <td>4.48</td>\n      <td>NaN</td>\n      <td>2.01</td>\n    </tr>\n    <tr>\n      <th>35087</th>\n      <td>37247901.0</td>\n      <td>https://www.airbnb.com/rooms/37247901</td>\n      <td>2023-09-07</td>\n      <td>Condo in Greater London Â· â˜…4.83 Â· Studio Â· 2 b...</td>\n      <td>Brand New Open Plan Studio Flat with Lift Acce...</td>\n      <td>144246094.0</td>\n      <td>Richard</td>\n      <td>2017-08-04</td>\n      <td>London, United Kingdom</td>\n      <td>We act as a property agency for a number of la...</td>\n      <td>...</td>\n      <td>$120.00</td>\n      <td>4</td>\n      <td>1125.0</td>\n      <td>75.0</td>\n      <td>29.0</td>\n      <td>2019-08-15</td>\n      <td>2023-08-27</td>\n      <td>4.83</td>\n      <td>NaN</td>\n      <td>0.59</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 34 columns</p>\n</div>\n```\n:::\n:::\n\n\nSee if you can work out from the documentation (Google search time!) how to get the same 'random' sample every time you re-run this code block:\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf.sample(3, ??)\n```\n\n#### Answer\n\n::: {#bee3e790 .cell execution_count=17}\n``` {.python .cell-code}\ndf.sample(3, random_state=42)\n```\n\n::: {.cell-output .cell-output-display execution_count=96}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>description</th>\n      <th>host_id</th>\n      <th>host_name</th>\n      <th>host_since</th>\n      <th>host_location</th>\n      <th>host_about</th>\n      <th>...</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n      <th>maximum_nights</th>\n      <th>availability_365</th>\n      <th>number_of_reviews</th>\n      <th>first_review</th>\n      <th>last_review</th>\n      <th>review_scores_rating</th>\n      <th>license</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25609</th>\n      <td>25934130.0</td>\n      <td>https://www.airbnb.com/rooms/25934130</td>\n      <td>2023-09-06</td>\n      <td>Home in Greater London Â· 1 bedroom Â· 1 bed Â· 2...</td>\n      <td>A huge, bright and quiet room in a lovely hous...</td>\n      <td>39113254.0</td>\n      <td>Pavlos</td>\n      <td>2015-07-21</td>\n      <td>London, United Kingdom</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>$18.00</td>\n      <td>30</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2018-12-03</td>\n      <td>2018-12-03</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>31738</th>\n      <td>33270886.0</td>\n      <td>https://www.airbnb.com/rooms/33270886</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· â˜…4.38 Â· 1 bedr...</td>\n      <td>Delightful and colourful one bedroom home floo...</td>\n      <td>28820321.0</td>\n      <td>Veronica</td>\n      <td>2015-03-05</td>\n      <td>London, United Kingdom</td>\n      <td>I moved to London to follow my love who is a L...</td>\n      <td>...</td>\n      <td>$80.00</td>\n      <td>2</td>\n      <td>1125.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>2019-05-01</td>\n      <td>2019-09-13</td>\n      <td>4.38</td>\n      <td>NaN</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5346</th>\n      <td>7005528.0</td>\n      <td>https://www.airbnb.com/rooms/7005528</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in London Â· â˜…4.67 Â· 1 bedroom Â· 1 ...</td>\n      <td>Flat has lots of light in a quiet private, pic...</td>\n      <td>36705667.0</td>\n      <td>Pablo</td>\n      <td>2015-06-25</td>\n      <td>London, United Kingdom</td>\n      <td>I am a sociable, responsible, tidy person and ...</td>\n      <td>...</td>\n      <td>$95.00</td>\n      <td>6</td>\n      <td>66.0</td>\n      <td>88.0</td>\n      <td>15.0</td>\n      <td>2015-07-05</td>\n      <td>2019-12-19</td>\n      <td>4.67</td>\n      <td>NaN</td>\n      <td>0.15</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 34 columns</p>\n</div>\n```\n:::\n:::\n\n\n::::\n\n## Selecting Columns \n\nIf you look very closely, you'll see that pandas isn't showing you the _full_ range of columns since there are 34! If you'd like to only look at specific columns then you can specify them after the sample method call using what looks like a nested list: `[[<column names as strings>]]`. \n\nI'd like you to sample 3 random rows, selecting the 'latitude', 'longitude', 'license', 'property_type', 'room_type' and 'price' columns only.\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf.sample(??)[??]\n```\n\n#### Answer\n\nNotice that we can make things a little easier to read using the whitespace:\n\n::: {#9cdfcd46 .cell execution_count=18}\n``` {.python .cell-code}\ndf.sample(3)[\n    ['latitude', 'longitude', 'license', 'property_type', 'room_type', 'price']\n]\n```\n\n::: {.cell-output .cell-output-display execution_count=97}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>license</th>\n      <th>property_type</th>\n      <th>room_type</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30245</th>\n      <td>51.59261</td>\n      <td>-0.09400</td>\n      <td>NaN</td>\n      <td>Entire loft</td>\n      <td>Entire home/apt</td>\n      <td>$65.00</td>\n    </tr>\n    <tr>\n      <th>24688</th>\n      <td>51.52219</td>\n      <td>-0.16565</td>\n      <td>NaN</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>$550.00</td>\n    </tr>\n    <tr>\n      <th>20851</th>\n      <td>51.54067</td>\n      <td>-0.14050</td>\n      <td>NaN</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>$112.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::::\n\n## Dealing with NaNs and Nulls\n\n::: {.callout-caution collapse=\"true\"}\n\n#### Difficulty: Hard. \n\nThere is a _lot_ going on here and you should be paying close attention.\n\n:::\n\nIf you really dig into the data you will see that a number of data types that aren't 'appropriate' for their contents: the id columns are floats; the dates aren't dates; there's a boolean that's not a boolean... It would be nice to fix these! \n\n```python\n# Add some columns here...\n```\n\n::: {.callout-note}\n\nI had intended to ask you to fix these by combining code from previous weeks with information provided in the lecture, but it turns out that the InsideAirbnb data set is *dirty*. There are a lot of `NaN` values and some of these are *deeply* problematic for some of the column types in pandas. There are also a number of challenges with other columns so, instead, I've opted to show you how I would clean this data as a *first pass* to get it into a format where it's tractable for further cleaning.\n\n:::\n\n### Identifying Problem Rows\n\nThe reason I'm not asking you to do this part yourselves is that it took me nearly an hour just to work out why I couldn't convert some of the columns to the right data types; then I started finding rows like these:\n\n::: {#429baf45 .cell execution_count=19}\n``` {.python .cell-code}\ndf[df.price.isna()]\n```\n\n::: {.cell-output .cell-output-display execution_count=98}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>description</th>\n      <th>host_id</th>\n      <th>host_name</th>\n      <th>host_since</th>\n      <th>host_location</th>\n      <th>host_about</th>\n      <th>...</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n      <th>maximum_nights</th>\n      <th>availability_365</th>\n      <th>number_of_reviews</th>\n      <th>first_review</th>\n      <th>last_review</th>\n      <th>review_scores_rating</th>\n      <th>license</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8668</th>\n      <td>1.012818e+07</td>\n      <td>https://www.airbnb.com/rooms/10128178</td>\n      <td>2023-09-06</td>\n      <td>Loft in London Â· â˜…4.15 Â· 2 bedrooms Â· 2 beds Â·...</td>\n      <td>This is a lived in apartment with two medium s...</td>\n      <td>233649.0</td>\n      <td>Michelle</td>\n      <td>2010-09-13</td>\n      <td>London, United Kingdom</td>\n      <td>Michelle McLaughlin -  A professional who work...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11814</th>\n      <td>1.359431e+07</td>\n      <td>https://www.airbnb.com/rooms/13594306</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in London Â· â˜…5.0 Â· 2 bedrooms Â· 2 ...</td>\n      <td>Beautiful quiet flat with high ceilings and lo...</td>\n      <td>18380563.0</td>\n      <td>CÃ©cile And Maarten</td>\n      <td>2014-07-19</td>\n      <td>London, United Kingdom</td>\n      <td>Hello! We live in London with our two daughter...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21912</th>\n      <td>2.206322e+07</td>\n      <td>https://www.airbnb.com/rooms/22063217</td>\n      <td>2023-09-07</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;Parejas</td>\n      <td>1824036.0</td>\n      <td>Arya</td>\n      <td>2012-02-28</td>\n      <td>London, United Kingdom</td>\n      <td>Citizen of the world.</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48138</th>\n      <td>5.342282e+07</td>\n      <td>https://www.airbnb.com/rooms/53422816</td>\n      <td>2023-09-06</td>\n      <td>Condo in London Â· â˜…4.93 Â· 1 bedroom Â· 1 bed Â· ...</td>\n      <td>We've newly refurbished our 1-bed apartment fo...</td>\n      <td>30626999.0</td>\n      <td>Sitara</td>\n      <td>2015-04-05</td>\n      <td>London, United Kingdom</td>\n      <td>Love travelling and meeting people!</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48765</th>\n      <td>5.389986e+07</td>\n      <td>https://www.airbnb.com/rooms/53899858</td>\n      <td>2023-09-06</td>\n      <td>Loft in Greater London Â· â˜…4.0 Â· 1 bedroom Â· 1 ...</td>\n      <td>Enjoy a stylish experience at this centrally-l...</td>\n      <td>233649.0</td>\n      <td>Michelle</td>\n      <td>2010-09-13</td>\n      <td>London, United Kingdom</td>\n      <td>Michelle McLaughlin -  A professional who work...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>68884</th>\n      <td>8.446589e+17</td>\n      <td>https://www.airbnb.com/rooms/844658929307006668</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>Stylish apartment Located in sought after neig...</td>\n      <td>10573878.0</td>\n      <td>Liz</td>\n      <td>2013-12-11</td>\n      <td>London, United Kingdom</td>\n      <td>I love hosting and meeting worldly guests trav...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>74896</th>\n      <td>8.971145e+17</td>\n      <td>https://www.airbnb.com/rooms/897114471991989638</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>Tucked away right off the high street, near 50...</td>\n      <td>11520835.0</td>\n      <td>Barry</td>\n      <td>2014-01-21</td>\n      <td>Levittown, NY</td>\n      <td>Hey there! born and raised in New York. Airbnb...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows Ã— 34 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#896844aa .cell execution_count=20}\n``` {.python .cell-code}\ndf[df.room_type.isna()]\n```\n\n::: {.cell-output .cell-output-display execution_count=99}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>description</th>\n      <th>host_id</th>\n      <th>host_name</th>\n      <th>host_since</th>\n      <th>host_location</th>\n      <th>host_about</th>\n      <th>...</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n      <th>maximum_nights</th>\n      <th>availability_365</th>\n      <th>number_of_reviews</th>\n      <th>first_review</th>\n      <th>last_review</th>\n      <th>review_scores_rating</th>\n      <th>license</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8668</th>\n      <td>1.012818e+07</td>\n      <td>https://www.airbnb.com/rooms/10128178</td>\n      <td>2023-09-06</td>\n      <td>Loft in London Â· â˜…4.15 Â· 2 bedrooms Â· 2 beds Â·...</td>\n      <td>This is a lived in apartment with two medium s...</td>\n      <td>233649.0</td>\n      <td>Michelle</td>\n      <td>2010-09-13</td>\n      <td>London, United Kingdom</td>\n      <td>Michelle McLaughlin -  A professional who work...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11814</th>\n      <td>1.359431e+07</td>\n      <td>https://www.airbnb.com/rooms/13594306</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in London Â· â˜…5.0 Â· 2 bedrooms Â· 2 ...</td>\n      <td>Beautiful quiet flat with high ceilings and lo...</td>\n      <td>18380563.0</td>\n      <td>CÃ©cile And Maarten</td>\n      <td>2014-07-19</td>\n      <td>London, United Kingdom</td>\n      <td>Hello! We live in London with our two daughter...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21912</th>\n      <td>2.206322e+07</td>\n      <td>https://www.airbnb.com/rooms/22063217</td>\n      <td>2023-09-07</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;Parejas</td>\n      <td>1824036.0</td>\n      <td>Arya</td>\n      <td>2012-02-28</td>\n      <td>London, United Kingdom</td>\n      <td>Citizen of the world.</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48138</th>\n      <td>5.342282e+07</td>\n      <td>https://www.airbnb.com/rooms/53422816</td>\n      <td>2023-09-06</td>\n      <td>Condo in London Â· â˜…4.93 Â· 1 bedroom Â· 1 bed Â· ...</td>\n      <td>We've newly refurbished our 1-bed apartment fo...</td>\n      <td>30626999.0</td>\n      <td>Sitara</td>\n      <td>2015-04-05</td>\n      <td>London, United Kingdom</td>\n      <td>Love travelling and meeting people!</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48765</th>\n      <td>5.389986e+07</td>\n      <td>https://www.airbnb.com/rooms/53899858</td>\n      <td>2023-09-06</td>\n      <td>Loft in Greater London Â· â˜…4.0 Â· 1 bedroom Â· 1 ...</td>\n      <td>Enjoy a stylish experience at this centrally-l...</td>\n      <td>233649.0</td>\n      <td>Michelle</td>\n      <td>2010-09-13</td>\n      <td>London, United Kingdom</td>\n      <td>Michelle McLaughlin -  A professional who work...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>68884</th>\n      <td>8.446589e+17</td>\n      <td>https://www.airbnb.com/rooms/844658929307006668</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>Stylish apartment Located in sought after neig...</td>\n      <td>10573878.0</td>\n      <td>Liz</td>\n      <td>2013-12-11</td>\n      <td>London, United Kingdom</td>\n      <td>I love hosting and meeting worldly guests trav...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>74896</th>\n      <td>8.971145e+17</td>\n      <td>https://www.airbnb.com/rooms/897114471991989638</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>Tucked away right off the high street, near 50...</td>\n      <td>11520835.0</td>\n      <td>Barry</td>\n      <td>2014-01-21</td>\n      <td>Levittown, NY</td>\n      <td>Hey there! born and raised in New York. Airbnb...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows Ã— 34 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#022c413b .cell execution_count=21}\n``` {.python .cell-code}\ndf[~(df.price.str.startswith('$', na=False))]\n```\n\n::: {.cell-output .cell-output-display execution_count=100}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>description</th>\n      <th>host_id</th>\n      <th>host_name</th>\n      <th>host_since</th>\n      <th>host_location</th>\n      <th>host_about</th>\n      <th>...</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n      <th>maximum_nights</th>\n      <th>availability_365</th>\n      <th>number_of_reviews</th>\n      <th>first_review</th>\n      <th>last_review</th>\n      <th>review_scores_rating</th>\n      <th>license</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8668</th>\n      <td>1.012818e+07</td>\n      <td>https://www.airbnb.com/rooms/10128178</td>\n      <td>2023-09-06</td>\n      <td>Loft in London Â· â˜…4.15 Â· 2 bedrooms Â· 2 beds Â·...</td>\n      <td>This is a lived in apartment with two medium s...</td>\n      <td>233649.0</td>\n      <td>Michelle</td>\n      <td>2010-09-13</td>\n      <td>London, United Kingdom</td>\n      <td>Michelle McLaughlin -  A professional who work...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8669</th>\n      <td>NaN</td>\n      <td>within an hour</td>\n      <td>71%</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>t</td>\n      <td>London, England, United Kingdom</td>\n      <td>Hackney</td>\n      <td>...</td>\n      <td>170</td>\n      <td>2023-09-06</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11814</th>\n      <td>1.359431e+07</td>\n      <td>https://www.airbnb.com/rooms/13594306</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in London Â· â˜…5.0 Â· 2 bedrooms Â· 2 ...</td>\n      <td>Beautiful quiet flat with high ceilings and lo...</td>\n      <td>18380563.0</td>\n      <td>CÃ©cile And Maarten</td>\n      <td>2014-07-19</td>\n      <td>London, United Kingdom</td>\n      <td>Hello! We live in London with our two daughter...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11815</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://a0.muscache.com/im/pictures/user/User-...</td>\n      <td>https://a0.muscache.com/im/pictures/user/User-...</td>\n      <td>1.0</td>\n      <td>t</td>\n      <td>t</td>\n      <td>London, United Kingdom</td>\n      <td>Brent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2023-09-06</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.07</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21912</th>\n      <td>2.206322e+07</td>\n      <td>https://www.airbnb.com/rooms/22063217</td>\n      <td>2023-09-07</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;Parejas</td>\n      <td>1824036.0</td>\n      <td>Arya</td>\n      <td>2012-02-28</td>\n      <td>London, United Kingdom</td>\n      <td>Citizen of the world.</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21913</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://a0.muscache.com/defaults/user_pic-50x5...</td>\n      <td>https://a0.muscache.com/defaults/user_pic-225x...</td>\n      <td>1.0</td>\n      <td>f</td>\n      <td>t</td>\n      <td>NaN</td>\n      <td>Tower Hamlets</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2023-09-07</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48138</th>\n      <td>5.342282e+07</td>\n      <td>https://www.airbnb.com/rooms/53422816</td>\n      <td>2023-09-06</td>\n      <td>Condo in London Â· â˜…4.93 Â· 1 bedroom Â· 1 bed Â· ...</td>\n      <td>We've newly refurbished our 1-bed apartment fo...</td>\n      <td>30626999.0</td>\n      <td>Sitara</td>\n      <td>2015-04-05</td>\n      <td>London, United Kingdom</td>\n      <td>Love travelling and meeting people!</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48139</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>83%</td>\n      <td>https://a0.muscache.com/im/pictures/user/3a51c...</td>\n      <td>https://a0.muscache.com/im/pictures/user/3a51c...</td>\n      <td>2.0</td>\n      <td>t</td>\n      <td>t</td>\n      <td>London, United Kingdom</td>\n      <td>Tower Hamlets</td>\n      <td>...</td>\n      <td>179</td>\n      <td>2023-09-06</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.75</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48765</th>\n      <td>5.389986e+07</td>\n      <td>https://www.airbnb.com/rooms/53899858</td>\n      <td>2023-09-06</td>\n      <td>Loft in Greater London Â· â˜…4.0 Â· 1 bedroom Â· 1 ...</td>\n      <td>Enjoy a stylish experience at this centrally-l...</td>\n      <td>233649.0</td>\n      <td>Michelle</td>\n      <td>2010-09-13</td>\n      <td>London, United Kingdom</td>\n      <td>Michelle McLaughlin -  A professional who work...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48766</th>\n      <td>NaN</td>\n      <td>within an hour</td>\n      <td>71%</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>t</td>\n      <td>NaN</td>\n      <td>Hackney</td>\n      <td>...</td>\n      <td>78</td>\n      <td>2023-09-06</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>68884</th>\n      <td>8.446589e+17</td>\n      <td>https://www.airbnb.com/rooms/844658929307006668</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>Stylish apartment Located in sought after neig...</td>\n      <td>10573878.0</td>\n      <td>Liz</td>\n      <td>2013-12-11</td>\n      <td>London, United Kingdom</td>\n      <td>I love hosting and meeting worldly guests trav...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>68885</th>\n      <td>NaN</td>\n      <td>a few days or more</td>\n      <td>6%</td>\n      <td>https://a0.muscache.com/im/pictures/user/7d57d...</td>\n      <td>https://a0.muscache.com/im/pictures/user/7d57d...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>t</td>\n      <td>NaN</td>\n      <td>Kensington and Chelsea</td>\n      <td>...</td>\n      <td>359</td>\n      <td>2023-09-06</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>74896</th>\n      <td>8.971145e+17</td>\n      <td>https://www.airbnb.com/rooms/897114471991989638</td>\n      <td>2023-09-06</td>\n      <td>Rental unit in Greater London Â· 1 bedroom Â· 1 ...</td>\n      <td>Tucked away right off the high street, near 50...</td>\n      <td>11520835.0</td>\n      <td>Barry</td>\n      <td>2014-01-21</td>\n      <td>Levittown, NY</td>\n      <td>Hey there! born and raised in New York. Airbnb...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>74897</th>\n      <td>NaN</td>\n      <td>within an hour</td>\n      <td>80%</td>\n      <td>https://a0.muscache.com/im/users/11520835/prof...</td>\n      <td>https://a0.muscache.com/im/users/11520835/prof...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>t</td>\n      <td>Greater London, England, United Kingdom</td>\n      <td>Ealing</td>\n      <td>...</td>\n      <td>157</td>\n      <td>2023-09-06</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>14 rows Ã— 34 columns</p>\n</div>\n```\n:::\n:::\n\n\nIf I had to guess, I'd say that it's some kind of partial extract/write process because there _are_ elements in some of the problem row(s) that look right but they are in the wrong columns. So we can _probably_ drop some of these rows, but one thing to do is look at the frequency of NaNs across the data frame _first_. So we need to look for NaNs and Nulls, but it's quite obvious that a `NaN` in the listing id is a basic problem and we should [drop these](https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/).\n\n::: {#354e1227 .cell execution_count=22}\n``` {.python .cell-code}\ndf[df.id.isna()][['id','listing_url','name','description','host_id','host_name','price']]\n```\n\n::: {.cell-output .cell-output-display execution_count=101}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>name</th>\n      <th>description</th>\n      <th>host_id</th>\n      <th>host_name</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8669</th>\n      <td>NaN</td>\n      <td>within an hour</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>11815</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://a0.muscache.com/im/pictures/user/User-...</td>\n      <td>https://a0.muscache.com/im/pictures/user/User-...</td>\n      <td>1.0</td>\n      <td>t</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21913</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://a0.muscache.com/defaults/user_pic-50x5...</td>\n      <td>https://a0.muscache.com/defaults/user_pic-225x...</td>\n      <td>1.0</td>\n      <td>f</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48139</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://a0.muscache.com/im/pictures/user/3a51c...</td>\n      <td>https://a0.muscache.com/im/pictures/user/3a51c...</td>\n      <td>2.0</td>\n      <td>t</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>48766</th>\n      <td>NaN</td>\n      <td>within an hour</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>https://a0.muscache.com/im/pictures/user/652bf...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>68885</th>\n      <td>NaN</td>\n      <td>a few days or more</td>\n      <td>https://a0.muscache.com/im/pictures/user/7d57d...</td>\n      <td>https://a0.muscache.com/im/pictures/user/7d57d...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>359</td>\n    </tr>\n    <tr>\n      <th>74897</th>\n      <td>NaN</td>\n      <td>within an hour</td>\n      <td>https://a0.muscache.com/im/users/11520835/prof...</td>\n      <td>https://a0.muscache.com/im/users/11520835/prof...</td>\n      <td>3.0</td>\n      <td>t</td>\n      <td>157</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAs always, if you don't know that's going on, break it down:\n\n- You have seen how column works (`[[<column names>]]`), so that's just selecting the columns that we want to show;\n- You know how row selection works (`df[<selection criteria>]`), so that isn't anything really new either;\n- So the only really new part is `df.id.isna()`: `df.id` is the `id` column (we could have written this `df['id']` if we wanted) and `isna()` is a test for whether or not a value is NaN. \n\nSo this shows that only one row in the 10,000 row sub-sample has a NaN for its id.\n\nIf you're not sure what the next line does, try breaking it down by running the inner bits before you run the `drop` command; and also try looking online for examples of how to use `df.drop` (e.g. just up above):\n\n::: {#e63a6ca9 .cell execution_count=23}\n``` {.python .cell-code}\ndf.drop(df[df.id.isna()].index.array, axis=0, inplace=True)\n```\n:::\n\n\nWith that really troublesome data out of the way, you can now turn to [counting NaNs or Nulls](https://www.delftstack.com/howto/python-pandas/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe/#df.isnull.sum-method-to-count-nan-occurrences) in the remaining data with a view to identifying other rows that can probably be dropped.\n\n### Counting Nulls by Column\n\nAs a starting point I would look to drop the columns that contain only NaNs. Remember that we've dropped a row from the data frame so our maximum is now $n-1$)! Notice how this next command works:\n```python\n# returns a data frame with all values set to True/False according to Null status\ndf.isnull() \n# counts these values by column (we'll see another option in a moment)\ndf.isnull.sum(axis=0) \n# Sort results in descending order\ndf.isnull.sum(axis=0).sort_values(ascending=False) \n```\n\n::: {#e607b959 .cell execution_count=24}\n``` {.python .cell-code}\ndf.isnull().sum(axis=0).sort_values(ascending=False)[:12]\n```\n\n::: {.cell-output .cell-output-display execution_count=103}\n```\nbathrooms               87946\nlicense                 87945\nhost_about              42040\nbedrooms                32781\nfirst_review            22164\nreviews_per_month       22164\nlast_review             22164\nreview_scores_rating    22164\nhost_location           18778\ndescription              1267\nbeds                     1141\nhost_is_superhost         939\ndtype: int64\n```\n:::\n:::\n\n\nThe most obvious ones here are: bathrooms, license, and host_about.\n\n::: {#caf6ba0a .cell execution_count=25}\n``` {.python .cell-code}\ndf.drop(columns=['bathrooms','license','host_about'], inplace=True)\n```\n:::\n\n\nBecause we have dropped everything `inplace` the code simply runs and doesn't return anything.\n\n### Counting Nulls by Row\n\nWe now know that there _are_ still quite a few problems, but we do still need a way to identify the rows that are causing most of the problems.\n\nNotice here that the change from `axis=0` to `axis=1` changes the 'direction' of the `sum` from columns to rows. And we are getting back a data series because the summing operation reduces it to just one column.\n\n::: {#723a7ded .cell execution_count=26}\n``` {.python .cell-code}\ndf.isnull().sum(axis=1).sort_values(ascending=False).head(20)\n```\n\n::: {.cell-output .cell-output-display execution_count=105}\n```\n48765    22\n8668     22\n21912    22\n68884    22\n48138    22\n11814    22\n74896    22\n7003     11\n6042     11\n5353     11\n4274     11\n6694     11\n2412      9\n39141     8\n39082     8\n40686     8\n27778     8\n39023     8\n1134      8\n611       8\ndtype: int64\n```\n:::\n:::\n\n\nSo that is Series showing how many NaN values there are by index value. You should see two columns of numbers: the first is the row id, the second is the number of Nulls in that row.\n\nIf we save the results to a variable called `probs` (i.e. problems) then we can decide what to do next.\n\n::: {.callout-warning}\n\nThere's a chance that Python will complain why you try to run the third line of code. This is particularly likely if you are using Anaconda Python directly (i.e. not Docker). In that case you need to add the code listed at the start of Task 5.\n\n:::\n\n::: {#c88485d9 .cell execution_count=27}\n``` {.python .cell-code}\nprobs = df.isnull().sum(axis=1)\nprint(type(probs))       # Note that this has returned a series!\nprobs.plot.hist(bins=30) # Oooooooh, check out what we can do with a series!\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.series.Series'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-28-output-2.png){width=610 height=411}\n:::\n:::\n\n\nLooking at this histogram, these look like two groups in the data so I would start there. I would take values greater than 3â€“5 as being ones that are most likely be problematic. We can use the index from `probs` to select out the rows we want to inspect from the main data frame.\n\nHere's another bit of code that bears unpacking:\n\n::: {#e24084a2 .cell execution_count=28}\n``` {.python .cell-code}\ncutoff = 5\ndf.drop(probs[probs > cutoff].index, inplace=True)\n```\n:::\n\n\n1. `probs > 5`: this selects only those rows in the 'probs' series whose value is greater than 5\n2. `probs[...].index` returns the index values from the Series, which we will then pass to the `drop` command.\n3. `df.drop(..., inplace=True)` will then drop the rows selected by `probs[probs>5].index`.\n\n::: {#dfb21afb .cell execution_count=29}\n``` {.python .cell-code}\nprint(f\"Have reduced data frame to: {df.shape[0]:,} rows and {df.shape[1]:,} columns\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHave reduced data frame to: 85,127 rows and 31 columns\n```\n:::\n:::\n\n\n# Using Indexes\n\nTo recap, when we use the `[[...]]` syntax we're taking a short-cut through the data by column (keeping all rows). The *full* syntax is `df[<row_selection>,<col_selection>]`. Only when we *don't* specify both does it then default to `df[<col_selection>]`. \n\nTo make the most of pandas you will need to get to grips with the logic than underpins this syntax. This is embedded in the idea of there being row and column indexes. These are *like* the columns `A`..`ZZ` and the rows 1..n in Excel. As you'll have seen in [the video](), these aren't considered *data*, they are ways to *access the data*. Unlike Excel, while every data frame must *have* an index, in pandas you can 'promote' or 'demote' any column to be used *as* an index. \n\nThe default row index is just the row number â€” this will be created for you if you don't specify something else when you create the data frame. The default column index is created from a file's column names (works for many types of data) but you can change these at any time.\n\n## Label and Numeric Indexing\n\nPerhaps this will (eventually) help to make it more clear:\n\n::: {#141f55ca .cell execution_count=30}\n``` {.python .cell-code}\ndf.loc[\n    [4552, 4554, 4556, 4557],\n    ['latitude','longitude','property_type','room_type','price']\n]\n```\n\n::: {.cell-output .cell-output-display execution_count=109}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>property_type</th>\n      <th>room_type</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4552</th>\n      <td>51.531070</td>\n      <td>-0.186060</td>\n      <td>Private room in rental unit</td>\n      <td>Private room</td>\n      <td>$95.00</td>\n    </tr>\n    <tr>\n      <th>4554</th>\n      <td>51.476640</td>\n      <td>-0.215200</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>$250.00</td>\n    </tr>\n    <tr>\n      <th>4556</th>\n      <td>51.400162</td>\n      <td>-0.076788</td>\n      <td>Private room in home</td>\n      <td>Private room</td>\n      <td>$56.00</td>\n    </tr>\n    <tr>\n      <th>4557</th>\n      <td>51.408920</td>\n      <td>-0.180910</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>$150.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAnd compare *that* with:\n\n::: {#8e9d32cf .cell execution_count=31}\n``` {.python .cell-code}\ndf.iloc[\n    4552:4557,\n    14:19\n]\n```\n\n::: {.cell-output .cell-output-display execution_count=110}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>property_type</th>\n      <th>room_type</th>\n      <th>accommodates</th>\n      <th>bathrooms_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4655</th>\n      <td>-0.15610</td>\n      <td>Private room in home</td>\n      <td>Private room</td>\n      <td>1.0</td>\n      <td>1 shared bath</td>\n    </tr>\n    <tr>\n      <th>4656</th>\n      <td>-0.11470</td>\n      <td>Private room in rental unit</td>\n      <td>Private room</td>\n      <td>1.0</td>\n      <td>1 bath</td>\n    </tr>\n    <tr>\n      <th>4657</th>\n      <td>-0.06745</td>\n      <td>Private room in rental unit</td>\n      <td>Private room</td>\n      <td>1.0</td>\n      <td>1 shared bath</td>\n    </tr>\n    <tr>\n      <th>4658</th>\n      <td>-0.24050</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>4.0</td>\n      <td>1 bath</td>\n    </tr>\n    <tr>\n      <th>4659</th>\n      <td>-0.18325</td>\n      <td>Private room in home</td>\n      <td>Private room</td>\n      <td>2.0</td>\n      <td>1 bath</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis code *seems* similar, but what are `iloc` and `loc`? The way I remember it is that `iloc` means *integer* location (as you would with *list indexing*), while `loc` means *label* location (as you would with *dictionary keys* or labels). I guess that should therefore be `lloc`, but you get the idea).\n\n## Numeric Indexes\n\nIn this case, the **index** (the numbers down the left-hand side in bold) is numeric, so we can treat it as a *label* (which allows us to use `df.loc`) *or* a list-type index (which allows us to use `df.iloc`). So with `loc` we refer to the columns by *label*, whereas with `iloc` we refer to them by *location*; as well, `loc` allows us to access rows and columns non-sequentially/randomly by label, while `iloc` allows us to access them as a numeric range.\n\n## Non-numeric Indexes\n\nNotice how this works differently if we specify a **non-numeric index**:\n\n::: {#3039c036 .cell execution_count=32}\n``` {.python .cell-code}\ndf.set_index('listing_url')[\n    ['latitude','longitude','property_type','room_type','price']\n].sample(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=111}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>property_type</th>\n      <th>room_type</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>listing_url</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>https://www.airbnb.com/rooms/762957927200510209</th>\n      <td>51.54788</td>\n      <td>-0.12084</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>$68.00</td>\n    </tr>\n    <tr>\n      <th>https://www.airbnb.com/rooms/22387033</th>\n      <td>51.53077</td>\n      <td>-0.13211</td>\n      <td>Private room in rental unit</td>\n      <td>Private room</td>\n      <td>$21.00</td>\n    </tr>\n    <tr>\n      <th>https://www.airbnb.com/rooms/771061462307304203</th>\n      <td>51.46530</td>\n      <td>-0.05178</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>$185.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNotice change in indexing because 'listing_url' is no longer a column, it's the index now!\n\n::: {#28565e69 .cell execution_count=33}\n``` {.python .cell-code}\ndf.set_index('listing_url').iloc[0:3,13:18] \n```\n\n::: {.cell-output .cell-output-display execution_count=112}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>property_type</th>\n      <th>room_type</th>\n      <th>accommodates</th>\n      <th>bathrooms_text</th>\n    </tr>\n    <tr>\n      <th>listing_url</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>https://www.airbnb.com/rooms/92644</th>\n      <td>-0.18739</td>\n      <td>Private room in rental unit</td>\n      <td>Private room</td>\n      <td>2.0</td>\n      <td>1.5 shared baths</td>\n    </tr>\n    <tr>\n      <th>https://www.airbnb.com/rooms/93015</th>\n      <td>-0.21707</td>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n      <td>5.0</td>\n      <td>1 bath</td>\n    </tr>\n    <tr>\n      <th>https://www.airbnb.com/rooms/13913</th>\n      <td>-0.11270</td>\n      <td>Private room in rental unit</td>\n      <td>Private room</td>\n      <td>1.0</td>\n      <td>1 shared bath</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.callout-caution}\n\nIt's vital that you understand how this code _works_. By which I mean _why_ it does something at all, not exactly how to use `loc` and `iloc` (though that is also useful).\n\n`df.set_index(...)` changes the index from the default row number to another field in the data frame. This operation _returns_ a new data frame with `listing_url` as its index. Because set index returned a data frame, we can simply add _another_ method call (`iloc` or `loc`) on to the end of that line and _it_ returns a new data frame in turn! \n    \nThe fact that each operation returns a new data frame (or data series) is why you can even do this:\n\n::: {#6d6dc630 .cell execution_count=34}\n``` {.python .cell-code}\n    df.set_index('listing_url').iloc[0:3].latitude.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=113}\n```\n51.50351666666666\n```\n:::\n:::\n\n\n:::\n\n# Fixing Data Types\n\nIf you want to challenge yourself, then I'd suggest trying to work out how to adapt what we saw in previous weeks using the data type dictionary to map column names to column types; however, a more straightforward way to do this is to create different for loops for each:\n\n##  Profiling (Optional)\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low.\n\n:::\n\nThe Pandas Profiling tool (rebranded a year or so back as [ydata-profiling](https://github.com/ydataai/ydata-profiling)) offers an alternative way of understanding what's going on in your data. The output [looks rather nice](https://docs.profiling.ydata.ai/) and you might be tempted to ask why we didn't use this straight away on the full data set -- well, if you really want to know, see what happens when you profile all 70,000-odd rows and 70-odd columns in the raw data frame... in effect: while it's 'nice to have', the likelihood of crashing your computer increases significantly and it's a bit of a tangent, so that's why it's no longer included in the Docker image.\n\nIf you *do* want to explore this then you'll need to install the library, and **this is a good chance to look at a quite sophisiticated way to install software on another machine**:\n\n```python\nfrom ydata_profiling import ProfileReport\n```\n\n### Specify the Profiling Columns\n\nLooking back over earlier code see if you can work out how to profile `latitude`, `longitude`,and `review_scores_rating` together.\n\n:::: {.qna}\n\n#### Question\n\n```python\nprofile = ProfileReport(??, title=\"Pandas Profiling Report\")\n```\n\n#### Answer\n\n```python\nprofile = ProfileReport(df[['latitude','longitude','review_scores_rating']], title=\"Pandas Profiling Report\")\n```\n\n::::\n\n### Profiling Targets\n\nYou can write the profile either directly into the Jupyter notebook (this file) or into a separate HTML (i.e. Web) page.\n\n```python\nprofile.to_notebook_iframe()\n# You can also write this profile to a web page:\n# profile.to_file(\"your_report.html\")\n```\n\n## Managing Memory\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low.\n\n:::\n\nAs to _why_ you'd want to fix your data types, there are two reasons: 1) to ensure that you can make the *most* of your data; 2) to ensure that it takes up as little space as possible in memory. Some simple examples:\n\n- A column containing only `'True'` (4 bytes) and `'False'` (5 bytes) will take up much more space than a column containing only `True` and `False` (1 bit each).\n- A column containing only `'Red'`, `'Green'`, and `'Blue'` (3, 5, and 4 bytes each respectively) will take up much more space that a column where we use the numbers `1, 2, 3` to represent these values and have a map that tells us `1==Red`, `2==Blue`, and `3==Green`.\n\nLet's test this idea out:\n\n::: {#459ba281 .cell execution_count=35}\n``` {.python .cell-code}\nrtm = df.room_type.memory_usage(deep=True) # Room Type Memory\nctm = df.room_type.astype('category').memory_usage(deep=True) # Categorical Type Memory\n\nprint(f\"The raw memory usage of `room_type` is {rtm/1024:,.0f} Kb.\")\nprint(f\"The categorical memory usage of `room_type` is {ctm/1024:,.0f} Kb.\")\nprint(f\"That's {(ctm/rtm)*100:.0f}% of the original!\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe raw memory usage of `room_type` is 7,958 Kb.\nThe categorical memory usage of `room_type` is 2,813 Kb.\nThat's 35% of the original!\n```\n:::\n:::\n\n\n::: {#2e91ad37 .cell execution_count=36}\n``` {.python .cell-code}\nshm = df.host_is_superhost.memory_usage(deep=True) # Super Host Memory\nbhm = df.host_is_superhost.replace({'f':False, 't':True}).astype('bool').memory_usage(deep=True) # Boolean Host Memory\n\nprint(f\"The raw memory usage of `host_is_superhost` is {shm/1024:,.0f} Kb.\")\nprint(f\"The boolean memory usage of `host_is_superhost` is {bhm/1024:,.0f} Kb.\")\nprint(f\"That's {(bhm/shm)*100:.0f}% of the original!\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe raw memory usage of `host_is_superhost` is 6,870 Kb.\nThe boolean memory usage of `host_is_superhost` is 2,812 Kb.\nThat's 41% of the original!\n```\n:::\n:::\n\n\n## Boolean Values\n\n::: {.callout-warning collapse=\"true\"}\n\n#### Difficulty: Moderate.\n\n:::\n\nLet's start with columns that are likely to be boolean:\n\n::: {#5fd1cbc5 .cell execution_count=37}\n``` {.python .cell-code}\nbools = ['host_is_superhost']\ndf.sample(5, random_state=43)[bools]\n```\n\n::: {.cell-output .cell-output-display execution_count=116}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host_is_superhost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55197</th>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>24505</th>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>44546</th>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>16312</th>\n      <td>t</td>\n    </tr>\n    <tr>\n      <th>66564</th>\n      <td>f</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nHere we have to `map` 't' to True and 'f' to False _before_ converting the column to a boolean type. If you simply tried to replace them with the strings 'True' and 'False', then the conversion would run into the same problem as Week 3: any string that is not `None` will convert a True boolean.\n\n::: {#0588749a .cell execution_count=38}\n``` {.python .cell-code}\n# This approach requires us to map 't' \n# and 'f' to True and False\nfor b in bools:\n    print(f\"Converting {b}\")\n    df[b] = df[b].replace({'f':False, 't':True}).astype('bool')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting host_is_superhost\n```\n:::\n:::\n\n\n::: {#6eed40b9 .cell execution_count=39}\n``` {.python .cell-code}\ndf.sample(5, random_state=43)[bools]\n```\n\n::: {.cell-output .cell-output-display execution_count=118}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host_is_superhost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55197</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24505</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>44546</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16312</th>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>66564</th>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Dates\n\n::: {.callout-caution collapse=\"true\"}\n\n#### Difficulty: Hard.\n\n:::\n\nI've found dates to be particularly challenging, though pandas has _tried_ to make this process less painful than it was a few years ago. What can be particularly frustrating is if _one_ row has a non-sensical date value (e.g. a `t`, as happened in 2019/20) then the entire type conversion will fail. When that happens, pandas is not great about communicating where the problem occurred and I had to work it out by trying to convert _parts_ of each series (using `.iloc`) to the datetime type until I had a block that failed. I then knew that I could narrow this down further using integer location indexing.\n\n::: {#b1309013 .cell execution_count=40}\n``` {.python .cell-code}\ndates = ['last_scraped','host_since','first_review','last_review']\n\nprint(f\"Currently {dates[1]} is of type '{df[dates[1]].dtype}'\", \"\\n\")\ndf.sample(5, random_state=43)[dates]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCurrently host_since is of type 'object' \n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=119}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>last_scraped</th>\n      <th>host_since</th>\n      <th>first_review</th>\n      <th>last_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55197</th>\n      <td>2023-09-07</td>\n      <td>2015-02-11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24505</th>\n      <td>2023-09-06</td>\n      <td>2012-12-18</td>\n      <td>2019-01-05</td>\n      <td>2020-01-05</td>\n    </tr>\n    <tr>\n      <th>44546</th>\n      <td>2023-09-06</td>\n      <td>2016-05-26</td>\n      <td>2021-08-15</td>\n      <td>2023-01-10</td>\n    </tr>\n    <tr>\n      <th>16312</th>\n      <td>2023-09-07</td>\n      <td>2017-04-02</td>\n      <td>2017-04-04</td>\n      <td>2023-08-26</td>\n    </tr>\n    <tr>\n      <th>66564</th>\n      <td>2023-09-06</td>\n      <td>2017-05-07</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#0bdab2b4 .cell execution_count=41}\n``` {.python .cell-code}\nfor d in dates:\n    print(\"Converting \" + d)\n    df[d] = pd.to_datetime(df[d])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting last_scraped\nConverting host_since\nConverting first_review\nConverting last_review\n```\n:::\n:::\n\n\n::: {#37cbe56d .cell execution_count=42}\n``` {.python .cell-code}\ndf.sample(5, random_state=43)[dates]\n```\n\n::: {.cell-output .cell-output-display execution_count=121}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>last_scraped</th>\n      <th>host_since</th>\n      <th>first_review</th>\n      <th>last_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55197</th>\n      <td>2023-09-07</td>\n      <td>2015-02-11</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>24505</th>\n      <td>2023-09-06</td>\n      <td>2012-12-18</td>\n      <td>2019-01-05</td>\n      <td>2020-01-05</td>\n    </tr>\n    <tr>\n      <th>44546</th>\n      <td>2023-09-06</td>\n      <td>2016-05-26</td>\n      <td>2021-08-15</td>\n      <td>2023-01-10</td>\n    </tr>\n    <tr>\n      <th>16312</th>\n      <td>2023-09-07</td>\n      <td>2017-04-02</td>\n      <td>2017-04-04</td>\n      <td>2023-08-26</td>\n    </tr>\n    <tr>\n      <th>66564</th>\n      <td>2023-09-06</td>\n      <td>2017-05-07</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOf course, it's not actually clear there what has changed! But if you dig a little more deeply:\n\n::: {#7b6e8e9b .cell execution_count=43}\n``` {.python .cell-code}\nprint(f\"Now {dates[1]} is of type '{df[dates[1]].dtype}'\", \"\\n\")\ndf.sample(5, random_state=45)[dates[1]].dt.strftime('%A %B %d, %Y')\n# Try some other formats!\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNow host_since is of type 'datetime64[ns]' \n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=122}\n```\n45006    Sunday December 15, 2013\n11882       Monday April 13, 2015\n74675     Wednesday July 16, 2014\n80039         Friday May 06, 2022\n84399       Friday April 22, 2022\nName: host_since, dtype: object\n```\n:::\n:::\n\n\nIn that line of code we:\n\n- Took a random sample (setting the state to 45),\n- Took the second column from the dates list (`dates[1]`),\n- Used the _date_ 'accessor method' (`.dt`), \n- And called `string format time` with the format `%A %B %d, %Y` (Full Day of Week, Month Name, Date, 4-digit Year)\n\n## Categories\n\n::: {.callout-warning collapse=\"true\"}\n\n#### Difficulty: Moderate.\n\n:::\n\nWe know that these are likely to be categories because there'd be no other way to allow users to effectively search Airbnb.\n\n::: {#2ee221c1 .cell execution_count=44}\n``` {.python .cell-code}\ncats = ['property_type','room_type']\n\nprint(f\"Currently {cats[1]} is of type '{df[cats[1]].dtype}'\", \"\\n\")\ndf.sample(5, random_state=42)[cats]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCurrently room_type is of type 'object' \n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=123}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>property_type</th>\n      <th>room_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18050</th>\n      <td>Private room in home</td>\n      <td>Private room</td>\n    </tr>\n    <tr>\n      <th>86868</th>\n      <td>Private room in home</td>\n      <td>Private room</td>\n    </tr>\n    <tr>\n      <th>54798</th>\n      <td>Private room in bed and breakfast</td>\n      <td>Private room</td>\n    </tr>\n    <tr>\n      <th>74233</th>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n    </tr>\n    <tr>\n      <th>87242</th>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis next piece of code is quite useful for grouping and counting operations: we are counting the occurences of each unique value in part particular column or combination of columns:\n\n::: {.longform}\n\n::: {#a1d04f54 .cell execution_count=45}\n``` {.python .cell-code}\ndf[cats[0]].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=124}\n```\nproperty_type\nEntire rental unit                   33450\nPrivate room in rental unit          13278\nPrivate room in home                  9795\nEntire condo                          8656\nEntire home                           7530\n                                     ...  \nYurt                                     1\nPrivate room in island                   1\nShared room in villa                     1\nShared room in serviced apartment        1\nTreehouse                                1\nName: count, Length: 99, dtype: int64\n```\n:::\n:::\n\n\n:::\n\n::: {.longform}\n\n::: {#ca74d8e7 .cell execution_count=46}\n``` {.python .cell-code}\ndf[cats[1]].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=125}\n```\nroom_type\nEntire home/apt    54203\nPrivate room       30366\nShared room          340\nHotel room           218\nName: count, dtype: int64\n```\n:::\n:::\n\n\n:::\n\n::: {.callout-tip}\n\nOne column has *many* different values (including Campers/RVs and Yurts!), the other has just four. If I were looking to conduct research I'd probably *start* with the `room_type` column since I may not care about hotels and therefore never even need to decide whether I care about boutique ones!\n\n:::\n\n::: {#ae29dbe5 .cell execution_count=47}\n``` {.python .cell-code}\nfor c in cats:\n    print(f\"Converting {c}\")\n    df[c] = df[c].astype('category')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting property_type\nConverting room_type\n```\n:::\n:::\n\n\n::: {#7ae2bb4d .cell execution_count=48}\n``` {.python .cell-code}\nprint(f\"Now {cats[1]} is of type '{df[cats[1]].dtype}'\", \"\\n\")\nprint(df[cats[1]].cat.categories.values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNow room_type is of type 'category' \n\n['Entire home/apt' 'Hotel room' 'Private room' 'Shared room']\n```\n:::\n:::\n\n\n::: {#ebb7a150 .cell execution_count=49}\n``` {.python .cell-code}\ndf.sample(5, random_state=42)[cats]\n```\n\n::: {.cell-output .cell-output-display execution_count=128}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>property_type</th>\n      <th>room_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18050</th>\n      <td>Private room in home</td>\n      <td>Private room</td>\n    </tr>\n    <tr>\n      <th>86868</th>\n      <td>Private room in home</td>\n      <td>Private room</td>\n    </tr>\n    <tr>\n      <th>54798</th>\n      <td>Private room in bed and breakfast</td>\n      <td>Private room</td>\n    </tr>\n    <tr>\n      <th>74233</th>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n    </tr>\n    <tr>\n      <th>87242</th>\n      <td>Entire rental unit</td>\n      <td>Entire home/apt</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Dealing with Strings\n\n::: {.callout-caution collapse=\"true\"}\n\n#### Difficulty: Hard.\n\n:::\n\nWe'll have to put some more work into deal with the description and other more free-from text fields later in the term, but for now let's just deal with a straightforward one: price!\n\n::: {#05fe4bdb .cell execution_count=50}\n``` {.python .cell-code}\nmoney = ['price']\ndf.sample(5, random_state=42)[money]\n```\n\n::: {.cell-output .cell-output-display execution_count=129}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18050</th>\n      <td>$51.00</td>\n    </tr>\n    <tr>\n      <th>86868</th>\n      <td>$56.00</td>\n    </tr>\n    <tr>\n      <th>54798</th>\n      <td>$45.00</td>\n    </tr>\n    <tr>\n      <th>74233</th>\n      <td>$104.00</td>\n    </tr>\n    <tr>\n      <th>87242</th>\n      <td>$126.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**You will get an error when you run the next code block**, that's because I want you to do a little thinking about how to extend the code to fix the data. You've already got the code you need to fix it, you just need to do a bit of thinking about 'method chaining'!\n\n::: {#d8e32bd4 .cell execution_count=51}\n``` {.python .cell-code}\nfor m in money:\n    print(f\"Converting {m}\")\n    try:\n        df[m] = df[m].str.replace('$','', regex=False).astype('float')\n    except ValueError as e:\n        print(f\"    xxxx Unable to convert {m} to float xxxx\")\n        print(e)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting price\n    xxxx Unable to convert price to float xxxx\ncould not convert string to float: '1,000.00'\n```\n:::\n:::\n\n\nLook closely at the error and then think about what you need to add to the code below:\n\n::: {.callout-note}\n\nFor now don't worry about what `regex=False` means. It will all make sense when we get to _dealing with text_.\n\n:::\n\n:::: {.qna}\n\n#### Question\n\n```python\nfor m in money:\n    print(f\"Converting {m}\")\n    df[m] = df[m].str.replace('$','', regex=False).str.replace(??).astype('float')\n```\n\n#### Answer\n\n::: {#07e33cab .cell execution_count=52}\n``` {.python .cell-code}\nfor m in money:\n    print(f\"Converting {m}\")\n    df[m] = df[m].str.replace('$','', regex=False).str.replace(',','').astype('float')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting price\n```\n:::\n:::\n\n\n::::\n\n::: {#74bf94db .cell execution_count=53}\n``` {.python .cell-code}\ndf.sample(5, random_state=42)[money]\n```\n\n::: {.cell-output .cell-output-display execution_count=132}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18050</th>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>86868</th>\n      <td>56.0</td>\n    </tr>\n    <tr>\n      <th>54798</th>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>74233</th>\n      <td>104.0</td>\n    </tr>\n    <tr>\n      <th>87242</th>\n      <td>126.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#cf95e186 .cell execution_count=54}\n``` {.python .cell-code}\ndf.sort_values(by='price', ascending=False).head(3)[['id','name','price','minimum_nights']]\n```\n\n::: {.cell-output .cell-output-display execution_count=133}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36168</th>\n      <td>3.845268e+07</td>\n      <td>Guesthouse in Dagenham Â· â˜…5.0 Â· 1 bedroom Â· 1 ...</td>\n      <td>80100.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11249</th>\n      <td>1.325477e+07</td>\n      <td>Rental unit in London Â· â˜…4.85 Â· 1 bedroom Â· 1 ...</td>\n      <td>53588.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>53708</th>\n      <td>6.454631e+17</td>\n      <td>Serviced apartment in Greater London Â· 4 bedro...</td>\n      <td>36000.0</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Dealing with Integers\n\n::: {.callout-caution collapse=\"true\"}\n\n#### Difficulty: Hard.\n\n:::\n\nThis is the issue that made me abandon the idea of making you clean the data yourselves. Although _floats_ have no issues with `np.nan` in the Series, by default there are no numpy integer arrays that can cope with NaNs. This was such a major issue for Pandas that they've actually created their _own_ data type that does support NaN values in integer columns. There are a lot of integer columns, but only one of them seems to be a problem.\n\n::: {#f0388c89 .cell execution_count=55}\n``` {.python .cell-code}\nints  = ['id','host_id','host_listings_count','host_total_listings_count','accommodates',\n         'beds','minimum_nights','maximum_nights','availability_365']\nfor i in ints:\n    print(f\"Converting {i}\")\n    try:\n        df[i] = df[i].astype('float').astype('int')\n    except ValueError as e:\n        print(\"  - !!!Converting to unsigned 16-bit integer!!!\")\n        df[i] = df[i].astype('float').astype(pd.UInt16Dtype())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting id\nConverting host_id\nConverting host_listings_count\nConverting host_total_listings_count\nConverting accommodates\nConverting beds\n  - !!!Converting to unsigned 16-bit integer!!!\nConverting minimum_nights\nConverting maximum_nights\nConverting availability_365\n```\n:::\n:::\n\n\nSo we convert the column but using a `try / except` approach that allows to trap `ValueError` exceptions triggered by the presence of NaNs in the column. The following code tells us that there are just eight of these in the 10k sample, but they're enough to cause the code to fail if you don't trap them. The alternatives would be to: a) drop those rows; or b) leave the data as floats. For some reason the latter offends my sense of order, and the former feels like avoiding the problem rather than dealing with it.\n\n::: {#f5c50c64 .cell execution_count=56}\n``` {.python .cell-code}\ndf.beds.isna().value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=135}\n```\nbeds\nFalse    84326\nTrue       801\nName: count, dtype: int64\n```\n:::\n:::\n\n\n## Validation\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low.\n\n:::\n\nOrdinarily, at this point I would then output information to confirm that all of the opeations I _think_ I've undertaken were correctly applied.\n\n```python\ndf.info()\n```\n\n## Saving\n\nAlso at this point I would save a copy of the cleaned data, though I would only consider this data _partially_ cleaned since we've not made it any further than just ensuring that each column is in an appropriate format and that some particularly problematic rows have been dropped!\n\n::: {#eacf92ed .cell execution_count=57}\n``` {.python .cell-code}\npath = os.path.join('data','clean')\n\nif not os.path.exists(path):\n    print(f\"Creating {path} under {os.getcwd()}\")\n    os.makedirs(path)\n    \ndf.to_csv(os.path.join(path,fn), index=False)\nprint(\"Done.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDone.\n```\n:::\n:::\n\n\nFeather is an alternative format (gradually being replaced by parquet, which is more widely supported) for data interchange between R and Python: it's fast, it preserves data types, it's compressed, and it will avoid the kinds of the problems that come up when you move to/from CSV as a default.\n\n# Selection using Criteria\n\nSo far we've been taking primarily a row and column view of the data, now we want to think about selecting ranges from within the data set...\n\n## Selecting using Data Types\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low.\n\n:::\n\nIf we wanted to filter in/out certain columns pandas can do that! Let's try for floats and ints (*hint*: these are 64-bit data types).\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf.select_dtypes(include=[??])\n```\n\n#### Answer\n\n::: {#658d0c97 .cell execution_count=58}\n``` {.python .cell-code}\ndf.select_dtypes(include=['float64','int64'])\n```\n\n::: {.cell-output .cell-output-display execution_count=137}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>host_id</th>\n      <th>host_listings_count</th>\n      <th>host_total_listings_count</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>accommodates</th>\n      <th>bedrooms</th>\n      <th>price</th>\n      <th>minimum_nights</th>\n      <th>maximum_nights</th>\n      <th>availability_365</th>\n      <th>number_of_reviews</th>\n      <th>review_scores_rating</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>92644</td>\n      <td>498201</td>\n      <td>1</td>\n      <td>1</td>\n      <td>51.442010</td>\n      <td>-0.187390</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>42.0</td>\n      <td>2</td>\n      <td>730</td>\n      <td>217</td>\n      <td>216.0</td>\n      <td>4.57</td>\n      <td>1.45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93015</td>\n      <td>499704</td>\n      <td>1</td>\n      <td>2</td>\n      <td>51.499930</td>\n      <td>-0.217070</td>\n      <td>5</td>\n      <td>2.0</td>\n      <td>175.0</td>\n      <td>5</td>\n      <td>240</td>\n      <td>40</td>\n      <td>38.0</td>\n      <td>4.82</td>\n      <td>0.27</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13913</td>\n      <td>54730</td>\n      <td>3</td>\n      <td>4</td>\n      <td>51.568610</td>\n      <td>-0.112700</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>360</td>\n      <td>41.0</td>\n      <td>4.80</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15400</td>\n      <td>60302</td>\n      <td>1</td>\n      <td>12</td>\n      <td>51.487800</td>\n      <td>-0.168130</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>150.0</td>\n      <td>7</td>\n      <td>30</td>\n      <td>73</td>\n      <td>94.0</td>\n      <td>4.80</td>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93734</td>\n      <td>497514</td>\n      <td>1</td>\n      <td>1</td>\n      <td>51.476180</td>\n      <td>0.014420</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>46.0</td>\n      <td>4</td>\n      <td>365</td>\n      <td>196</td>\n      <td>180.0</td>\n      <td>4.62</td>\n      <td>1.21</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87947</th>\n      <td>973779750539727232</td>\n      <td>518599414</td>\n      <td>4</td>\n      <td>4</td>\n      <td>51.410424</td>\n      <td>-0.183070</td>\n      <td>6</td>\n      <td>2.0</td>\n      <td>119.0</td>\n      <td>1</td>\n      <td>365</td>\n      <td>318</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>87948</th>\n      <td>973781286754517248</td>\n      <td>498408783</td>\n      <td>2</td>\n      <td>2</td>\n      <td>51.514860</td>\n      <td>-0.135980</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>275.0</td>\n      <td>2</td>\n      <td>1125</td>\n      <td>239</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>87949</th>\n      <td>973801695874775168</td>\n      <td>36645347</td>\n      <td>1</td>\n      <td>1</td>\n      <td>51.459042</td>\n      <td>-0.055458</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>3</td>\n      <td>21</td>\n      <td>88</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>87951</th>\n      <td>973882998775928064</td>\n      <td>439074505</td>\n      <td>2538</td>\n      <td>5217</td>\n      <td>51.450997</td>\n      <td>-0.444319</td>\n      <td>10</td>\n      <td>5.0</td>\n      <td>680.0</td>\n      <td>1</td>\n      <td>365</td>\n      <td>364</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>87952</th>\n      <td>973895808066047616</td>\n      <td>475112423</td>\n      <td>37</td>\n      <td>47</td>\n      <td>51.515970</td>\n      <td>-0.111342</td>\n      <td>6</td>\n      <td>2.0</td>\n      <td>170.0</td>\n      <td>1</td>\n      <td>365</td>\n      <td>297</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>85127 rows Ã— 15 columns</p>\n</div>\n```\n:::\n:::\n\n\n::::\n\n## Selecting using Conditions\n\n::: {.callout-caution collapse=\"true\"}\n\n#### Difficulty: Hard.\n\n:::\n\nWhat if we wanted to find whole homes listings for more than $100/night? \n\nTo do this we use a combination of the selection approaches above in combination with conditionals, but first we need to see what sort of properties there are in the data set! `groupby` is a really useful function that we'll come back to later in the term, but for now notice that it helps us to group the analysis by `room_type` so that subsequently asking for the `property_type` value counts allows the same `property_type` to appear in more than once place if it's associated with more than one `room_type`.\n\n::: {#f0182163 .cell execution_count=59}\n``` {.python .cell-code}\ndf.groupby('room_type')['property_type'].value_counts()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/lk/__v0sp155qqfhjx0fmfkvw8c0000gn/T/ipykernel_38529/1894770798.py:1: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=138}\n```\nroom_type        property_type            \nEntire home/apt  Entire rental unit           33450\n                 Entire condo                  8656\n                 Entire home                   7530\n                 Entire serviced apartment     2021\n                 Entire townhouse              1153\n                                              ...  \nShared room      Tent                             0\n                 Tiny home                        0\n                 Tower                            0\n                 Treehouse                        0\n                 Yurt                             0\nName: count, Length: 396, dtype: int64\n```\n:::\n:::\n\n\nNow try to select only the `Entire home/apt` room type:\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf[df.??=='??']['property_type'].value_counts().head(10)\n```\n\nYour output should be:\n\n::: {#e5e0344f .cell execution_count=60}\n\n::: {.cell-output .cell-output-display execution_count=139}\n```\nproperty_type\nEntire rental unit           33450\nEntire condo                  8656\nEntire home                   7530\nEntire serviced apartment     2021\nEntire townhouse              1153\nEntire loft                    389\nEntire guesthouse              205\nEntire guest suite             178\nEntire vacation home           102\nBoat                            68\nName: count, dtype: int64\n```\n:::\n:::\n\n\n#### Answer\n\n::: {#7dc9deda .cell execution_count=61}\n``` {.python .cell-code}\ndf[df.room_type=='Entire home/apt']['property_type'].value_counts().head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=140}\n```\nproperty_type\nEntire rental unit           33450\nEntire condo                  8656\nEntire home                   7530\nEntire serviced apartment     2021\nEntire townhouse              1153\nEntire loft                    389\nEntire guesthouse              205\nEntire guest suite             178\nEntire vacation home           102\nBoat                            68\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::::\n\n## Arbitrary Selection Criteria\n\n::: {.callout-warning collapse=\"true\"}\n\n#### Difficulty: Moderate, if the previous section made sense to you.\n\n::: \n\nOK, now let's look for the Entire home/apt listings that are more expected than average... to do *that* let's get a sense of where the mean and median value fall:\n\n:::: {.qna}\n\n#### Question\n\n```python\nprint(f\"The mean price is ${df.price.??():0.2f}\")\nprint(f\"The median price is ${df.price.??():0.2f}\")\n```\n\n#### Answer\n\n::: {#8ba5ded6 .cell execution_count=62}\n``` {.python .cell-code}\nprint(f\"The mean price is ${df.price.mean():0.2f}\")\nprint(f\"The median price is ${df.price.median():0.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe mean price is $183.63\nThe median price is $112.00\n```\n:::\n:::\n\n\n::::\n\nYou should see that the mean is higher than the median price but both are _very_ roughly plausible values. Given your understanding of distributions from, say, Quantitative Methods, what can you say about the pricing distribution of Airbnb units?\n\nYou might want to have a [look at the documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#series): it's rather a long list, but most of your descriptive stats are on that page in the [Cumulative / Descriptive Stats](http://pandas.pydata.org/pandas-docs/stable/api.html#computations-descriptive-stats) section, and there's also lots of information about methods for [strings](http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling) and [categorical data](http://pandas.pydata.org/pandas-docs/stable/api.html#categorical).\n\n### Filtering: it's 'logical'\n\nSo we want to take `Entire home/apt` and filter the data set _together with_ the price per night from the `price` column.  For that, let's use the mean price/night of $183\\.63 (_note_: this is totally arbitrary)?\n\n:::: {.qna}\n\n#### Question\n\nSo here we want to filter on two values in the data set using `&`:\n\n```python\npricey = df[(??) & (df.price>df.price.??)]\nprint(f\"Selected {pricey.shape[0]:,} rows\")\n```\n\n#### Answer\n\nSo here we want to filter on two values in the data set using `&`:\n\n::: {#f24965a1 .cell execution_count=63}\n``` {.python .cell-code}\npricey = df[(df.room_type=='Entire home/apt') & (df.price>df.price.mean())]\nprint(f\"Selected {pricey.shape[0]:,} rows\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSelected 21,491 rows\n```\n:::\n:::\n\n\n::::\n\nIn the code above we see two things:\n\n1. The use of the bitwise `&` (it's *not* the same as `and`).\n2. The fact that you need parentheses around the selection in order to make the the `&` work.\n\n\n## Selection with an Aggregate\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low.\n\n:::\n\nLet's find the cheapest and most expensive listings using `min` and `max` methods:\n\n:::: {.qna}\n\n#### Question\n\nLeast expensive: \n\n```python\ndf[df.price==df.price.??()][['price','id','listing_url','room_type','description']]\n```\n\nMost expensive: \n\n```python\ndf[df.price==df.price.??()][['price','id','listing_url','room_type','description']]\n```\n\n#### Answer\n\nLeast expensive: \n\n::: {#ce60079f .cell execution_count=64}\n``` {.python .cell-code}\ndf[df.price==df.price.min()][['price','listing_url','room_type','description']]\n```\n\n::: {.cell-output .cell-output-display execution_count=143}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>listing_url</th>\n      <th>room_type</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36926</th>\n      <td>0.0</td>\n      <td>https://www.airbnb.com/rooms/39366016</td>\n      <td>Private room</td>\n      <td>Panoramic 9th floor skyline view. Quality inte...</td>\n    </tr>\n    <tr>\n      <th>37059</th>\n      <td>0.0</td>\n      <td>https://www.airbnb.com/rooms/39546721</td>\n      <td>Private room</td>\n      <td>Panoramic 9th floor skyline view. Private Balc...</td>\n    </tr>\n    <tr>\n      <th>70224</th>\n      <td>0.0</td>\n      <td>https://www.airbnb.com/rooms/857748607244683463</td>\n      <td>Private room</td>\n      <td>Room in a two-bedroom flat excellently located...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nMost expensive: \n\n::: {#e74fdc5d .cell execution_count=65}\n``` {.python .cell-code}\ndf[df.price==df.price.max()][['price','listing_url','room_type','description']]\n```\n\n::: {.cell-output .cell-output-display execution_count=144}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>listing_url</th>\n      <th>room_type</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36168</th>\n      <td>80100.0</td>\n      <td>https://www.airbnb.com/rooms/38452677</td>\n      <td>Entire home/apt</td>\n      <td>Bouquet design open plan house. &lt;br /&gt;Beautifu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::::\n\nYou should see one or more units priced at exceedingly high levels... and here's a way to see a few more of these budget-busting options.\n\n::: {#ff6b3f44 .cell execution_count=66}\n``` {.python .cell-code}\ndf.sort_values(by='price', ascending=False).head(3)[\n    ['price','listing_url','room_type','description']\n]\n```\n\n::: {.cell-output .cell-output-display execution_count=145}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>listing_url</th>\n      <th>room_type</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36168</th>\n      <td>80100.0</td>\n      <td>https://www.airbnb.com/rooms/38452677</td>\n      <td>Entire home/apt</td>\n      <td>Bouquet design open plan house. &lt;br /&gt;Beautifu...</td>\n    </tr>\n    <tr>\n      <th>11249</th>\n      <td>53588.0</td>\n      <td>https://www.airbnb.com/rooms/13254774</td>\n      <td>Private room</td>\n      <td>PLEASE NOTE THIS IS NO LONGER AVAILABLE! Cosy ...</td>\n    </tr>\n    <tr>\n      <th>53708</th>\n      <td>36000.0</td>\n      <td>https://www.airbnb.com/rooms/645463113262447532</td>\n      <td>Entire home/apt</td>\n      <td>Enjoy your stay in London in a modern, archite...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.callout-caution}\n\n#### Stop: Ask yourself if the result is _plausible_.\n\n:::\n\n:::: {.qna}\n\n#### Question\n\nWhat do you make of this result?\n\n#### Answer\n\nTry following some of the `listing_url`s. My best *guess* is that some people are having trouble *un*-listing their properties or are somehow trying to pause bookings by pricing their property at an unrealistical level.\n\n::::\n\n## Selection with a Range\n\n::: {.callout-warning collapse=\"true\"}\n\n#### Difficulty: Moderate\n\n:::\n\nPerhaps we aren't just looking for extremes... how about all of the properties falling within the middle of the distribution? We can ask for any abitrary quantile we like, so let's go with the 25th and 75th percentile to get the middle 50% of the data. Google how to get percentiles from pandas.\n\n:::: {.qna}\n\n#### Question\n\n```python\ndfr = df[ \n            (df.price > df.price.quantile(??)) & \n            (df.price < df.price.quantile(??)) ]\n\nprint(f\"Lower Quartile: {df.price.quantile(??):>6.2f}\")\nprint(f\"Upper Quartile: {df.price.quantile(??):>6.2f}\")\nprint()\nprint(f\"Range selected contains {dfr.shape[0]:,} rows.\")\nprint(f\"Minimum price: {dfr.price.??():>6.2f}\")\nprint(f\"Maximum price: {dfr.price.??():>6.2f}\")\n```\n\n#### Answer\n\n::: {#8981b255 .cell execution_count=67}\n``` {.python .cell-code}\ndfr = df[\n            (df.price > df.price.quantile(0.25)) &\n            (df.price < df.price.quantile(0.75)) ]\n\nprint(f\"Lower Quartile: {df.price.quantile(0.25):>6.2f}\")\nprint(f\"Upper Quartile: {df.price.quantile(0.75):>6.2f}\")\nprint()\nprint(f\"Range selected contains {dfr.shape[0]:,} rows.\")\nprint(f\"Minimum price: {dfr.price.min():>6.2f}\")\nprint(f\"Maximum price: {dfr.price.max():>6.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLower Quartile:  65.00\nUpper Quartile: 196.00\n\nRange selected contains 41,575 rows.\nMinimum price:  66.00\nMaximum price: 195.00\n```\n:::\n:::\n\n\n::::\n\nThat example contains a few things to which you need to pay attention:\n\n1. *Again* you can see that, with mutiple selections, we had to put parentheses around each one -- this forces Python to...\n2. Process the `&` (bit-wise AND) that asks pandas to \"Find all the rows where condition 1 _and_ condition 2 are both `True`\". So it calculates the `True`/`False` for the left side and the `True`/`False` for the right side of the `&`, and then combines them.\n\n# Enhancing our Understanding\n\n## Deriving a New Variable\n\n::: {.callout-caution collapse=\"true\"}\n\n#### Difficulty: &#129327;\n\n:::\n\nLet's try calculating several derived measures of distribution for the price... these deliberately demonstrate different ways of handling this process (and notice also the little call to `apply` that can perform additional tasks).\n\n### The *z*-Score\n\nThe z-score is given by $z = (x - \\bar{x})/\\sigma$.\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf['z'] = (df.?? - df.??.??()) / df.??.??()\ndf.z.describe().apply(lambda x: f\"{x:5.5f}\")\n```\n\n#### Answer\n\n::: {#0ea24b78 .cell execution_count=68}\n``` {.python .cell-code}\ndf['z'] = (df.price - df.price.mean()) / df.price.std()\ndf.z.describe().apply(lambda x: f\"{x:5.5f}\")\n```\n\n::: {.cell-output .cell-output-display execution_count=147}\n```\ncount    85127.00000\nmean        -0.00000\nstd          1.00000\nmin         -0.37452\n25%         -0.24195\n50%         -0.14609\n75%          0.02524\nmax        162.99418\nName: z, dtype: object\n```\n:::\n:::\n\n\n::::\n\n### Inter-Quartile Standardisation\n\nThe IQR-standardised score is given by $i = (x - Q_{1})/(Q_{3} - Q_{1})$\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf['iqs'] = (df.price - ??)/(??-??)\ndf.iqs.describe().apply(lambda x: f\"{x:5.5f}\")\n```\n\n#### Answer\n\n::: {#2170972f .cell execution_count=69}\n``` {.python .cell-code}\ndf['iqs'] = (df.price - df.price.quantile(0.25))/(df.price.quantile(0.75)-df.price.quantile(0.25))\ndf.iqs.describe().apply(lambda x: f\"{x:5.5f}\")\n```\n\n::: {.cell-output .cell-output-display execution_count=148}\n```\ncount    85127.00000\nmean         0.90554\nstd          3.74276\nmin         -0.49618\n25%          0.00000\n50%          0.35878\n75%          1.00000\nmax        610.95420\nName: iqs, dtype: object\n```\n:::\n:::\n\n\n::::\n\n### Log-Normalisation\n\nThe natural log of the price is gven by $ln(x)$\n\n:::: {.qna}\n\n#### Question\n\n```python\ndf['lnprice'] = np.log(??)\ndf.lnprice.describe().apply(lambda x: f\"{x:5.5f}\")\n```\n\n#### Answer\n\n*Note* the issue with `divide by zero` here: you would need to resolve this by either dropping properties priced at `0`, *or* adding `1` to the price (i.e. `np.log(df.price+1)`). There are arguments for and against both approaches.\n\n::: {#9b837bf7 .cell execution_count=70}\n``` {.python .cell-code}\ndf['lnprice'] = np.log(df.price)\ndf.lnprice.describe().apply(lambda x: f\"{x:5.5f}\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/jreades/anaconda3/envs/sds/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ndivide by zero encountered in log\n\n/Users/jreades/anaconda3/envs/sds/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=149}\n```\ncount    85127.00000\nmean            -inf\nstd              nan\nmin             -inf\n25%          4.17439\n50%          4.71850\n75%          5.27811\nmax         11.29103\nName: lnprice, dtype: object\n```\n:::\n:::\n\n\n::::\n\n## Quick (and Dirty) Plotting\n\nOne of the first things we should do when exploring a new dataset is plot (aka graph) the data. We've left plotting until a little later in this practical so that we could see some other basic attributes of how pandas stores data. We'll look at plotting and exploratory data analyses in much more detail next week, including using packages other than pandas. \n\nFor now, let's look at the basic plotting functionality pandas provides - in conjunctions with the online documentation for both [DataFrames](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) and [Series](https://pandas.pydata.org/pandas-docs/stable/reference/index.html). There are also examples of all [the different types of plots pandas can produce](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html).\n\n::: {.callout-warning collapse=\"true\"}\n\n#### MacOS plotting *without* Docker\n\nMacOS users who are *not* using Docker will need to do certain things in a specific order at the start of any notebook in order to show maps or graphs. Please make a copy of the following code for any notebook that you create and make it the *first* code that you run in the notebook...\n\n```python\n# Needed on a Mac\nimport matplotlib as mpl\nmpl.use('TkAgg')\n%matplotlib inline\nimport matplotlib.pyplot as plt\n```\n\n:::\n\n### Histograms\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nFirst, let's see some of the ways we could visualise the distribution of the `Series` in the dataset:\n\n::: {#de61231e .cell execution_count=71}\n``` {.python .cell-code}\ndf.price.plot.hist() # histogram\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-72-output-1.png){width=610 height=411}\n:::\n:::\n\n\nIf the code worked properly you should have just created a standard [histogram](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.hist.html) plot (if you can't see one, ask for help). However, a basic problem here may be the range of the data: if your maximum price is much more than Â£5,000 then you'll find the majority of your data plotted in one bar, which isn't very helpful.\n\nYou can filter the data *and* pass in some simple options to improve the plotting:\n\n::: {#a31b55fb .cell execution_count=72}\n``` {.python .cell-code}\n# Notice the ';' here to suppress `<AxesSubplot...>`\n# That information doesn't *always* appear, but whenever\n# you have unwanted textual output above your plot just\n# add a ';' on the end of the line of code!\ndf[df.price < 1000].price.plot.hist(bins=50); \n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-73-output-1.png){width=610 height=411}\n:::\n:::\n\n\n### KDE Plots\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nSimilarly, we can produce a [Kernel Density Estimate plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.kde.html). This time, instead of dropping data just before calling `plot` we're going to modify the *limits* of the x-axis using `xlim`:\n\n:::: {.qna}\n\n#### Question\n\nLook for information about using `xlim`:\n\n```python\ndf.price.plot.kde(xlim=(??)); #kernel density estimate plot\n```\n\n#### Answer\n\n::: {#5cb3da1e .cell execution_count=73}\n``` {.python .cell-code}\ndf.price.plot.kde(xlim=(0,1000)); #kernel density estimate plot\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-74-output-1.png){width=631 height=411}\n:::\n:::\n\n\n::::\n\nKind of handy, no? These aren't the _best_ looking plots, but they are all being generated on-the-fly for you by pandas with no more than a cheery `DataFrame.Series.plot.<plot type>`! Since those plots are all just method calls, many of them take optional parameters to change the colour, the notation (scientific or not), and other options. For example, many of the documentation pages linked to above are rather brief, but include a link to [the general options that can be applied to all `Series.plot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.html) calls.\n\nThis is why we like pandas: it allows us to be _constructively lazy_. We don't need to know _how_ a draw a KDE plot (though it always helps if you don't see what you expected), we just need to know that pandas provides a method that will do it for you. And _that_ is why it's always worth having a [look at the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/index.html). \n\n### A Slight Case of Over-Plotting\n\nGenerally, Jupyter is clever enough to overlay plots one on top of the other if you call them all in the same cell. We'll see ways to gain more control later, but this is still a good start! Note that here we also need to get rid of the `-inf` values from rows that had a price of Â£0.\n\n::: {.callout-warning}\n\n#### Bug Alert {{< fa bug-slash >}}\n\nThe more we use pandas to sort and filter data the more you will start to see a `SettingWithCopyWarning`. This happens because of an interaction between how Pandas works and how Python works: when you are working with a very large data set you don't want to make a 'deep copy' of the data structure every time you make a change to the data. Instead, you get a 'view' into the data using a reference, which is a just a lightweight shortcut. So what happens when you try to modify that lightweight copy? Well, if you want to drop rows or columns then you either want to make a `copy()` at that point, or you will have to accept the warning *and* the computational risks that go with it.\n\n:::\n\n::: {#5528cde2 .cell execution_count=74}\n``` {.python .cell-code}\n# Calling copy() ensures the index is updated\n# and note that all subsequent plots will have\n# these Â£0 rows removed!\ndf = df[df.price > 0].copy() \ndf.z.plot.kde(xlim=[-2, 10])\ndf.iqs.plot.kde(xlim=[-2, 10])\ndf.lnprice.plot.kde();\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-75-output-1.png){width=606 height=411}\n:::\n:::\n\n\n### Boxplots\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nA standard [boxplot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.box.html):\n\n::: {#d8a2f43c .cell execution_count=75}\n``` {.python .cell-code}\ndf.lnprice.plot.box(figsize=(4, 8));\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-76-output-1.png){width=343 height=633}\n:::\n:::\n\n\n### Scatterplots\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nWe can also plot two variables in a [scatter plot](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter) by applying a plot method to the `DataFrame` (not an individual `Series`):\n\n::: {#f8e71d56 .cell execution_count=76}\n``` {.python .cell-code}\ndf.plot.scatter(x='longitude', y='latitude', c='price', s=2, cmap='viridis', figsize=(15,10))\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-77-output-1.png){width=1141 height=803}\n:::\n:::\n\n\nNote how the code above has the form `DataFrame.plot.<plot type>`, not `DataFrame.Series.plot.<plot type>` as in the prior plots. Think about why this then means we need the `x` and `y` arguments. \n\nLooking at the plot produced, it's hard to see where the high values are, so we might want to think about ways that we could make it easier to spot the big numbers... We could, for instance, also vary the size of the point in a plot by some variable, but why does the following not really work?\n\n::: {#7d3b836e .cell execution_count=77}\n``` {.python .cell-code}\ndf.plot.scatter(x='longitude', y='latitude', c='price', s=(df.price/df.price.min()), cmap='viridis', figsize=(15,10))\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-78-output-1.png){width=1141 height=803}\n:::\n:::\n\n\nAnd we can plot subsets of our data without creating a new object. See if you can work out what the following code is doing that is different from the last plot:\n\n::: {#768511e9 .cell execution_count=78}\n``` {.python .cell-code}\ndf[df.price > df.price.quantile(0.90)].plot.scatter(x='longitude', y='latitude', c='price', cmap='viridis', s=8)\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-79-output-1.png){width=616 height=434}\n:::\n:::\n\n\n### Hex Bin Plots\n\n::: {.callout-tip collapse=\"true\"}\n\n#### Difficulty: Low\n\n:::\n\nAnd pandas allows us to create 'less standard' plots, like a [hex bin plot](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.hexbin.html#pandas.DataFrame.plot.hexbin):\n\n::: {#66aac54b .cell execution_count=79}\n``` {.python .cell-code}\ndf.plot.hexbin(x='longitude', y='latitude', gridsize=50, figsize=(10,7))\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-05-Numeric_Data_files/figure-html/cell-80-output-1.png){width=778 height=581}\n:::\n:::\n\n\nThat's just a taste of what the basic plotting functionality of pandas can do. Feel free to explore more yourself and we'll also see [the seaborn package](http://seaborn.pydata.org/index.html) later.\n\n# Credits!\n\n#### License\nThese teaching materials are licensed under a mix of [The MIT License](https://opensource.org/licenses/mit-license.php) and the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 license](https://creativecommons.org/licenses/by-nc-sa/4.0/).\n\n#### Acknowledgements:\nSupported by the [Royal Geographical Society](https://www.rgs.org/HomePage.htm) (with the Institute of British Geographers) with a Ray Y Gildea Jr Award.\n\n#### Potential Dependencies:\nThis notebook may depend on the following libraries: pandas, matplotlib\n\n",
    "supporting": [
      "Practical-05-Numeric_Data_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}