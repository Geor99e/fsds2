{
  "hash": "9e9b2ed2e094241ad97409849860f3a9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Practical 10: Visualisation\"\nsubtitle: \"Linking & Visualising Data\"\njupyter: python3\nfilters:\n  - qna\n  - quarto\n---\n\n\n| Complete | Part 1: Foundations | Part 2: Data | Part 3: Analysis |     |\n| :------- | :------------------ | :----------- | :--------------- | --: |\n| 90% | &#9619;&#9619;&#9619;&#9619;&#9619;&#9619;&#9619;&#9619; | &#9619;&#9619;&#9619;&#9619;&#9619;&#9619; | &#9619;&#9619;&#9619;&#9619;&#9619;&#9617; | 10/10\n\n::: {.callout-warning}\n\n#### Important\n\nThis practical focusses on two key bits of _implementation_: visualisation and data linkage! You will have seen quite a bit of each of these across the preceding three to four weeks, but they were picked up in an _ad-hoc_ way, here we try to systematise things a bit.\n\n:::\n\n::: {.callout-note}\n\n#### &#128279; Connections\n\nHere we're trying to tidy up the loose ends. You've already worked with basic data visualisations in Seaborn and Matplotlib (including (geo)panda's `plot` function), but we want you to have a better sense of how that _works_ as part of a coherent -- if altogether rather complex and overwhelming -- approach to managing a data visualisation. You've also already seen examples of joins and spatial joins before but, again, we just want to review them more formally now.\n\n:::\n\n# Preamble\n\n::: {#1fe28ea0 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport seaborn as sns\n\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {#eb13eaa0 .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nfrom requests import get\nfrom urllib.parse import urlparse\n\ndef cache_data(src:str, dest:str) -> str:\n    \"\"\"Downloads and caches a remote file locally.\n    \n    The function sits between the 'read' step of a pandas or geopandas\n    data frame and downloading the file from a remote location. The idea\n    is that it will save it locally so that you don't need to remember to\n    do so yourself. Subsequent re-reads of the file will return instantly\n    rather than downloading the entire file for a second or n-th itme.\n    \n    Parameters\n    ----------\n    src : str\n        The remote *source* for the file, any valid URL should work.\n    dest : str\n        The *destination* location to save the downloaded file.\n        \n    Returns\n    -------\n    str\n        A string representing the local location of the file.\n    \"\"\"\n    \n    url = urlparse(src) # We assume that this is some kind of valid URL \n    fn  = os.path.split(url.path)[-1] # Extract the filename\n    dfn = os.path.join(dest,fn) #Â Destination filename\n    \n    # Check if dest+filename does *not* exist -- \n    # that would mean we have to download it!\n    if not os.path.isfile(dfn) or os.path.getsize(dfn) < 1:\n        \n        print(f\"{dfn} not found, downloading!\")\n\n        # Convert the path back into a list (without)\n        # the filename -- we need to check that directories\n        # exist first.\n        path = os.path.split(dest)\n        \n        # Create any missing directories in dest(ination) path\n        # -- os.path.join is the reverse of split (as you saw above)\n        # but it doesn't work with lists... so I had to google how\n        # to use the 'splat' operator! os.makedirs creates missing\n        # directories in a path automatically.\n        if len(path) >= 1 and path[0] != '':\n            os.makedirs(os.path.join(*path), exist_ok=True)\n            \n        # Download and write the file\n        with open(dfn, \"wb\") as file:\n            response = get(src)\n            file.write(response.content)\n            \n        print('Done downloading...')\n\n    else:\n        print(f\"Found {dfn} locally!\")\n\n    return dfn\n```\n:::\n\n\n# Spatial Joins (Recap)\n\n## Load Geodata\n\nA lot of useful geo-data can be accessed from the [GeoPortal](https://geoportal.statistics.gov.uk/). And see also [my discussion](https://jreades.github.io/fsds/lectures/9.2-Linking_Spatial_Data.html#/think-it-through) on [lookup tables](https://geoportal.statistics.gov.uk/datasets/postcode-to-output-area-to-lower-layer-super-output-area-to-middle-layer-super-output-area-to-local-authority-district-november-2018-lookup-in-the-uk-2/about).\n\n::: {#25b7a011 .cell execution_count=3}\n``` {.python .cell-code}\nspath = 'https://github.com/jreades/fsds/blob/master/data/src/' # source path\nddir  = os.path.join('data','geo') # destination directory\nwater = gpd.read_file( cache_data(spath+'Water.gpkg?raw=true', ddir) )\nboros = gpd.read_file( cache_data(spath+'Boroughs.gpkg?raw=true', ddir) )\ngreen = gpd.read_file( cache_data(spath+'Greenspace.gpkg?raw=true', ddir) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound data/geo/Water.gpkg locally!\nFound data/geo/Boroughs.gpkg locally!\nFound data/geo/Greenspace.gpkg locally!\n```\n:::\n:::\n\n\n::: {#0c450fd3 .cell execution_count=4}\n``` {.python .cell-code}\nmsoas = gpd.read_file( cache_data(spath+'Middle_Layer_Super_Output_Areas__December_2011__EW_BGC_V2-shp.zip?raw=true', ddir) )\nmsoas.plot();\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound data/geo/Middle_Layer_Super_Output_Areas__December_2011__EW_BGC_V2-shp.zip locally!\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-5-output-2.png){width=404 height=411}\n:::\n:::\n\n\n::: {#f6ae2b1a .cell execution_count=5}\n``` {.python .cell-code}\nmsoas.sample(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>MSOA11CD</th>\n      <th>MSOA11NM</th>\n      <th>MSOA11NMW</th>\n      <th>BNG_E</th>\n      <th>BNG_N</th>\n      <th>LONG</th>\n      <th>LAT</th>\n      <th>Shape__Are</th>\n      <th>Shape__Len</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6592</th>\n      <td>6593</td>\n      <td>E02006734</td>\n      <td>Worcester 001</td>\n      <td>Worcester 001</td>\n      <td>384974</td>\n      <td>257845</td>\n      <td>-2.22135</td>\n      <td>52.21862</td>\n      <td>4.544143e+06</td>\n      <td>11177.509085</td>\n      <td>POLYGON ((385548.000 258720.406, 385839.819 25...</td>\n    </tr>\n    <tr>\n      <th>4821</th>\n      <td>4822</td>\n      <td>E02004930</td>\n      <td>St Albans 007</td>\n      <td>St Albans 007</td>\n      <td>517022</td>\n      <td>210632</td>\n      <td>-0.30498</td>\n      <td>51.78213</td>\n      <td>1.443424e+07</td>\n      <td>19701.770584</td>\n      <td>POLYGON ((518548.281 212950.402, 518553.781 21...</td>\n    </tr>\n    <tr>\n      <th>6481</th>\n      <td>6482</td>\n      <td>E02006623</td>\n      <td>Worthing 003</td>\n      <td>Worthing 003</td>\n      <td>511678</td>\n      <td>104975</td>\n      <td>-0.41547</td>\n      <td>50.83353</td>\n      <td>1.435652e+06</td>\n      <td>8182.321431</td>\n      <td>POLYGON ((512686.730 105645.721, 512562.698 10...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Select London MSOAs\n\n::: {.callout-note}\n\n#### &#128279; Connections\n\nOne thing to remember here is that computers are _exact_. So if you say that the selection should only be of MSOAs _within_ London then you actually need to think about whether a shared border qualifies as 'within'. Watch [the lectures](https://jreades.github.io/fsds/sessions/week10.html#lectures) again if you're unsure, but that's why here we take this slightly clunk approach of buffering the London boundary _before_ doing the selection.\n\n:::\n\n### Union\n\nAs we don't have a boundary file for London, we can *generate* use using the `unary_union` operator (as we do here) or using the [dissolve()](https://geopandas.org/en/stable/docs/user_guide/aggregation_with_dissolve.html) approach. Consider the pros and cons of each approach in terms of performance, output format, and leigibility. \n\nSo here's approach 1, which is a function call (on which we call `plot`):\n\n::: {#fe7ba226 .cell execution_count=6}\n``` {.python .cell-code}\nboros.dissolve().plot();\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-7-output-1.png){width=558 height=411}\n:::\n:::\n\n\nAnd here's approach 2, which is an *attribute* and returns a polygon (so no reason to call `plot`, but it's come back without the rest of the data frame!):\n\n::: {#c179d7e8 .cell execution_count=7}\n``` {.python .cell-code}\nboros.unary_union\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n![](Practical-08-Selecting_Data_files/figure-html/cell-8-output-1.svg){}\n:::\n:::\n\n\n::: {.callout-note}\n\n#### &#128279; Connections\n\nNotice how we're also demonstrating some additional ways of plotting 'on the fly' (without generating a data frame) as well as reminding you how to zoom in/out.\n\n:::\n\n::: {#28e027e5 .cell execution_count=8}\n``` {.python .cell-code}\nldn = gpd.GeoDataFrame(gpd.GeoSeries(data=boros.unary_union)).rename(columns={0:'geometry'}).set_geometry(\"geometry\")\nldn = ldn.set_crs(epsg=27700)\nax  = ldn.plot(facecolor=(.5, .5, .9, .5));\nmsoas.plot(ax=ax, facecolor='none', edgecolor=(.6, .6, .6, .6))\nax.set_xlim(500000, 515000)\nax.set_ylim(180000, 195000);\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-9-output-1.png){width=450 height=411}\n:::\n:::\n\n\n### Buffer\n\nIn order to ensure that we get all MSOAs _within_ London we will buffer the boundary by 250m. If _cover_ were easier to use then that option might be preferable.\n\n:::: {.qna}\n\n#### Question\n\n```python\nldn['buffered'] = ldn.geometry.???(???)\nldn = ldn.set_geometry('buffered').set_crs(epsg=27700)\nax  = ldn.plot(facecolor=(.5, .5, .9, .5))\nmsoas.plot(ax=ax, facecolor='none', edgecolor=(.6, .6, .6, .6))\nax.set_xlim(500000, 515000)\nax.set_ylim(180000, 195000);\n```\n\n#### Answer\n\n::: {#0a4baee1 .cell execution_count=9}\n``` {.python .cell-code}\nldn['buffered'] = ldn.geometry.buffer(250)\nldn = ldn.set_geometry('buffered').set_crs(epsg=27700)\nax  = ldn.plot(facecolor=(.5, .5, .9, .5))\nmsoas.plot(ax=ax, facecolor='none', edgecolor=(.6, .6, .6, .6))\nax.set_xlim(500000, 515000)\nax.set_ylim(180000, 195000);\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-10-output-1.png){width=450 height=411}\n:::\n:::\n\n\n::::\n\n### Spatial Join\n\nHere's our first spatial join. By default it will be an _inner_ join because we want to drop everything that doesn't line up between the two data sets (i.e. don't keep the thousands of *other* MSOAs).\n\n:::: {.qna}\n\n#### Question\n\n```python\nldn_msoas = gpd.sjoin(msoas, ldn, predicate='???', how='inner')\nldn_msoas.head(2)\n```\n\n#### Answer\n\n::: {#6f992fc2 .cell execution_count=10}\n``` {.python .cell-code}\nldn_msoas = gpd.sjoin(msoas, ldn, predicate='within', how='inner')\nldn_msoas.head(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>MSOA11CD</th>\n      <th>MSOA11NM</th>\n      <th>MSOA11NMW</th>\n      <th>BNG_E</th>\n      <th>BNG_N</th>\n      <th>LONG</th>\n      <th>LAT</th>\n      <th>Shape__Are</th>\n      <th>Shape__Len</th>\n      <th>geometry_left</th>\n      <th>index_right</th>\n      <th>geometry_right</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>E02000001</td>\n      <td>City of London 001</td>\n      <td>City of London 001</td>\n      <td>532384</td>\n      <td>181355</td>\n      <td>-0.093490</td>\n      <td>51.51561</td>\n      <td>2.906361e+06</td>\n      <td>8936.818478</td>\n      <td>POLYGON ((532135.138 182198.131, 532158.250 18...</td>\n      <td>0</td>\n      <td>POLYGON ((528150.200 159979.200, 528100.900 16...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>E02000002</td>\n      <td>Barking and Dagenham 001</td>\n      <td>Barking and Dagenham 001</td>\n      <td>548267</td>\n      <td>189685</td>\n      <td>0.138756</td>\n      <td>51.58652</td>\n      <td>2.166163e+06</td>\n      <td>8150.405928</td>\n      <td>POLYGON ((548881.563 190845.265, 548881.125 19...</td>\n      <td>0</td>\n      <td>POLYGON ((528150.200 159979.200, 528100.900 16...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::::\n\n### Plot\n\n::: {#d3d0b3bf .cell execution_count=11}\n``` {.python .cell-code}\nldn_msoas.plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-12-output-1.png){width=579 height=425}\n:::\n:::\n\n\n:::: {.qna}\n\n#### Question\n\nHmmmm, not quite what you were expecting? See if you can figure out from the list of columns and the documentation for `set_geometry` what is going wrong?\n\n#### Answer\n\n::: {#79ad6f4f .cell execution_count=12}\n``` {.python .cell-code}\nax = ldn_msoas.set_geometry('geometry_left').plot(linewidth=2, facecolor='none', edgecolor=(.6, .6, .6, .6))\nax.set_xlim(500000, 515000)\nax.set_ylim(180000, 195000);\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-13-output-1.png){width=450 height=411}\n:::\n:::\n\n\n::::\n\n::: {#6e8a9487 .cell execution_count=13}\n``` {.python .cell-code}\nldn_msoas = ldn_msoas.rename(columns={'geometry_left':'geometry'}).set_geometry('geometry')\n```\n:::\n\n\n::: {#bf717f36 .cell execution_count=14}\n``` {.python .cell-code}\nldn_msoas.drop(columns='geometry_right', inplace=True)\n```\n:::\n\n\nWe no longer really need to keep the full MSOA data set hanging about.\n\n::: {#bdb80141 .cell execution_count=15}\n``` {.python .cell-code}\ntry:\n    del(msoas)\nexcept NameError:\n    print(\"msoas already deleted.\")\n```\n:::\n\n\n:::: {.qna}\n\n### Question\n\n- Can you explain *why* the outputs of the `dissolve` and `unary_union` *look* differnet? And use that as the basis for explaining why they *are* different?\n\n> \n\n- How do you know that the units for the buffering operation are metres? 250 could be *anything* right?\n\n> \n\n- Why do we need to buffer the London geometry *before* performing the *within* spatial join?\n\n> \n\n#### Answer\n\n- Can you explain *why* the outputs of the `dissolve` and `unary_union` *look* differnet? And use that as the basis for explaining why they *are* different?\n\n> Dissolve is a method call that returns a new GeoDataFrame, while unary_union is a spatial operation that returns a primitive geometry. So we could capture the output of dissolve and just r\nename the columns, but from unary_union we need to write the primitive *into* a new GeoDataFrame as a geometry column.\n\n- How do you know that the units for the buffering operation are metres? 250 could be *anything* right?\n\n> It depends on the CRS! EPSG:27700 uses metres so the buffer operation is in metres.\n\n- Why do we need to buffer the London geometry *before* performing the *within* spatial join?\n\n> Because there may be small precision issues such that the MSOA borders cross the 'border' of the Thames and therefore no longer fall entirely within the London geometry. Try it yourself by\n changing the buffer amount!\n\n::::\n\n## Append Names\n\nWe don't actually make use of these in this session, but *both* operations could be relevant to your final reports:\n\n1. The Borough > Subregion mapping could help you to group your data into larger sets so that your resulst become more reobust. it also connects us to long-run patterns of socio-economic development in London.\n2. The MSOA Names data set gives you something that you could use to label one or more 'neighbourhoods' on a map with names that are *relevant*. So rather than talking about \"As you can see, Sutton 003, is...\", you can write \"The Wrythe neighbourhood [or area] of Sutton is significantly different from the surrounding areas...\"\n\nThey also usefully test your understanding of regular expressions and a few other aspects covered in previous weeks.\n\n### Replace\n\nYou've done this before: notice that the MSOA Name _contains_ the Borough name **with a space and some digits at the end**. Use a regex (in `str.replace()`) to extract the LA name from the MSOA name. See if you do this *without* having to find your previous answer!\n\n:::: {.qna}\n\n#### Question\n\n```python\nldn_msoas['Borough'] = ldn_msoas.MSOA11NM.str.replace(r'???','',regex=True)\n\n# Just check results look plausible; you should have:\n# - 33 boroughs\n# - A df shape of 983 x 13\nprint(ldn_msoas.Borough.unique())\nprint(f\"There are {len(ldn_msoas.Borough.unique())} boroughs.\")\nprint(f\"Overall shape of data frame is {' x '.join([str(x) for x in ldn_msoas.shape])}\")\n```\n\n#### Answer\n\n::: {#32707b95 .cell execution_count=16}\n``` {.python .cell-code}\nldn_msoas['Borough'] = ldn_msoas.MSOA11NM.str.replace(r' \\d+$','',regex=True)\n\n# Just check results look plausible; you should have:\n# - 33 boroughs\n# - A df shape of 983 x 13\nprint(ldn_msoas.Borough.unique())\nprint(f\"There are {len(ldn_msoas.Borough.unique())} boroughs.\")\nprint(f\"Overall shape of data frame is {' x '.join([str(x) for x in ldn_msoas.shape])}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['City of London' 'Barking and Dagenham' 'Barnet' 'Bexley' 'Brent'\n 'Bromley' 'Camden' 'Croydon' 'Ealing' 'Enfield' 'Greenwich' 'Hackney'\n 'Hammersmith and Fulham' 'Haringey' 'Harrow' 'Havering' 'Hillingdon'\n 'Hounslow' 'Islington' 'Kensington and Chelsea' 'Kingston upon Thames'\n 'Lambeth' 'Lewisham' 'Merton' 'Newham' 'Redbridge' 'Richmond upon Thames'\n 'Southwark' 'Sutton' 'Tower Hamlets' 'Waltham Forest' 'Wandsworth'\n 'Westminster']\nThere are 33 boroughs.\nOverall shape of data frame is 983 x 13\n```\n:::\n:::\n\n\n::::\n\n### Merge\n\nThe House of Commons Library provides a [MSOA Names](https://houseofcommonslibrary.github.io/msoanames/) data set that contains locally-relevant names applied to MSOAs. These seek to connect the Census geography (OA > LSOA > MSOA > LA) to a loosely-defined 'neighbourhood'.\n\n::: {#86e0c0b4 .cell execution_count=17}\n``` {.python .cell-code}\nmsoa_nms = pd.read_csv( cache_data('https://houseofcommonslibrary.github.io/msoanames/MSOA-Names-1.20.csv', ddir) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound data/geo/MSOA-Names-1.20.csv locally!\n```\n:::\n:::\n\n\n::: {#2312d820 .cell execution_count=18}\n``` {.python .cell-code}\nprint(msoa_nms.columns.values)\nmsoa_nms.sample(3, random_state=42)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['msoa11cd' 'msoa11nm' 'msoa11nmw' 'msoa11hclnm' 'msoa11hclnmw' 'Laname']\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>msoa11cd</th>\n      <th>msoa11nm</th>\n      <th>msoa11nmw</th>\n      <th>msoa11hclnm</th>\n      <th>msoa11hclnmw</th>\n      <th>Laname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4512</th>\n      <td>E02004616</td>\n      <td>Cotswold 002</td>\n      <td>Cotswold 002</td>\n      <td>Moreton &amp; Stow-on-the-Wold</td>\n      <td>NaN</td>\n      <td>Cotswold</td>\n    </tr>\n    <tr>\n      <th>4660</th>\n      <td>E02004768</td>\n      <td>Havant 007</td>\n      <td>Havant 007</td>\n      <td>Waterlooville East</td>\n      <td>NaN</td>\n      <td>Havant</td>\n    </tr>\n    <tr>\n      <th>1038</th>\n      <td>E02001074</td>\n      <td>Manchester 030</td>\n      <td>Manchester 030</td>\n      <td>Fallowfield West &amp; Whalley Range South</td>\n      <td>NaN</td>\n      <td>Manchester</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow that you've loaded the `msoa_nms` data you need to merge it with our `ldn_msoas`. You will need to deal with the fact that the left and right fields have different names and may also want to think about the `how` of the merge. In *this* case, the result of the merge *should* be a GeoDataFrame, but **this is not always guaranteed** so you may want to double-check or run multiple tests before assuming that you'll get back a geographically aware object.\n\n:::: {.qna}\n\n#### Question\n\n```python\nmsoas = pd.merge(ldn_msoas, msoa_nms, left_on='??', right_on='??', how='??')\nprint(f\"MSOAs shape is {' x '.join([str(x) for x in msoas.shape])}.\")\nprint(f\"Resulting class is a {type(msoas).__name__}.\") # You should check this -- result isn't always be a GeoDataFrame\nmsoas.sample(3, random_state=42)[['OBJECTID','MSOA11CD','MSOA11NM','msoa11hclnm']]\n```\n\n#### Answer\n\n::: {#991c1edc .cell execution_count=19}\n``` {.python .cell-code}\nmsoas = pd.merge(ldn_msoas, msoa_nms, left_on='MSOA11CD', right_on='msoa11cd', how='inner')\nprint(f\"MSOAs shape is {' x '.join([str(x) for x in msoas.shape])}.\")\nprint(f\"Resulting class is a {type(msoas).__name__}.\") # You should check this -- result isn't always be a GeoDataFrame\nmsoas.sample(3, random_state=42)[['OBJECTID','MSOA11CD','MSOA11NM','msoa11hclnm']]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMSOAs shape is 983 x 19.\nResulting class is a GeoDataFrame.\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>MSOA11CD</th>\n      <th>MSOA11NM</th>\n      <th>msoa11hclnm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>810</th>\n      <td>811</td>\n      <td>E02000841</td>\n      <td>Sutton 002</td>\n      <td>St Helier South</td>\n    </tr>\n    <tr>\n      <th>801</th>\n      <td>802</td>\n      <td>E02000832</td>\n      <td>Southwark 026</td>\n      <td>Nunhead North</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>E02000844</td>\n      <td>Sutton 005</td>\n      <td>The Wrythe</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::::\n\nYour result should be:\n\n::: {#e99c14c6 .cell execution_count=20}\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>MSOA11CD</th>\n      <th>MSOA11NM</th>\n      <th>msoa11hclnm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>810</th>\n      <td>811</td>\n      <td>E02000841</td>\n      <td>Sutton 002</td>\n      <td>St Helier South</td>\n    </tr>\n    <tr>\n      <th>801</th>\n      <td>802</td>\n      <td>E02000832</td>\n      <td>Southwark 026</td>\n      <td>Nunhead North</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>E02000844</td>\n      <td>Sutton 005</td>\n      <td>The Wrythe</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Map\n\nSet up a `mapping` dict here so that you can apply it as part of the `groupby` operation below (you should have 33 keys when done):\n\n::: {#1a740192 .cell execution_count=21}\n``` {.python .cell-code}\nmapping = {}\nfor b in ['Enfield','Waltham Forest','Redbridge','Barking and Dagenham','Havering','Greenwich','Bexley']:\n    mapping[b]='Outer East and North East'\nfor b in ['Haringey','Islington','Hackney','Tower Hamlets','Newham','Lambeth','Southwark','Lewisham']:\n    mapping[b]='Inner East'\nfor b in ['Bromley','Croydon','Sutton','Merton','Kingston upon Thames']:\n    mapping[b]='Outer South'\nfor b in ['Wandsworth','Kensington and Chelsea','Hammersmith and Fulham','Westminster','Camden']:\n    mapping[b]='Inner West'\nfor b in ['Richmond upon Thames','Hounslow','Ealing','Hillingdon','Brent','Harrow','Barnet','City of London']:\n    mapping[b]='Outer West and North West'\nprint(len(mapping.keys()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n33\n```\n:::\n:::\n\n\n:::: {.qna}\n\n#### Question\n\n```python\nmsoas['Subregion'] = msoas.Borough.map(???)\n```\n\n#### Answer\n\n::: {#aea98a16 .cell execution_count=22}\n``` {.python .cell-code}\nmsoas['Subregion'] = msoas.Borough.map(mapping)\n```\n:::\n\n\n::::\n\n### Tidy Up\n\n::: {#65b18196 .cell execution_count=23}\n``` {.python .cell-code}\nmsoas.columns.to_list()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n['OBJECTID',\n 'MSOA11CD',\n 'MSOA11NM',\n 'MSOA11NMW',\n 'BNG_E',\n 'BNG_N',\n 'LONG',\n 'LAT',\n 'Shape__Are',\n 'Shape__Len',\n 'geometry',\n 'index_right',\n 'Borough',\n 'msoa11cd',\n 'msoa11nm',\n 'msoa11nmw',\n 'msoa11hclnm',\n 'msoa11hclnmw',\n 'Laname',\n 'Subregion']\n```\n:::\n:::\n\n\n::: {#1e5a0696 .cell execution_count=24}\n``` {.python .cell-code}\nto_drop = ['MSOA11CD','MSOA11NM','MSOA11NMW','LONG','LAT','Shape__Are','Shape__Len','index_right',\n           'Laname','msoa11hclnmw','msoa11nmw']\nmsoas.drop(columns=to_drop, inplace=True)\nprint(msoas.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(983, 9)\n```\n:::\n:::\n\n\n### And Save\n\n::: {#80370578 .cell execution_count=25}\n``` {.python .cell-code}\nmsoas.to_parquet(os.path.join('data','geo','London_MSOA_Names.geoparquet'))\n```\n:::\n\n\n## Load InsideAirbnb Data\n\n::: {#ec207465 .cell execution_count=26}\n``` {.python .cell-code}\nhost = 'http://orca.casa.ucl.ac.uk'\npath = '~jreades/data'\nymd  = '2023-09-06'\nlistings = gpd.read_parquet( cache_data(f'{host}/{path}/{ymd}-listings.geoparquet', ddir) )\nlistings = listings.to_crs(epsg=27700)\nprint(f\"Data frame is {listings.shape[0]:,} x {listings.shape[1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound data/geo/2023-09-06-listings.geoparquet locally!\nData frame is 85,134 x 31\n```\n:::\n:::\n\n\n::: {#03efb128 .cell execution_count=27}\n``` {.python .cell-code}\nlistings = listings.to_crs('epsg:27700')\n```\n:::\n\n\n### Spatial Join\n\nAssociate LA (Local Authority) names to the listings using a spatial join, but **notice** the `how` here:\n\n:::: {.qna}\n\n#### Question\n\n```python\ngdf_la = gpd.sjoin(listings, ???, predicate='???', how='left')\nprint(gdf_la.columns.to_list())\n```\n\n#### Answer\n\n::: {#574e9a44 .cell execution_count=28}\n``` {.python .cell-code}\ngdf_la = gpd.sjoin(listings, boros, predicate='within', how='left')\nprint(gdf_la.columns.to_list())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['listing_url', 'last_scraped', 'name', 'description', 'host_id', 'host_name', 'host_since', 'host_location', 'host_is_superhost', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights', 'availability_365', 'number_of_reviews', 'first_review', 'last_review', 'review_scores_rating', 'reviews_per_month', 'geometry', 'index_right', 'NAME', 'GSS_CODE', 'HECTARES', 'NONLD_AREA', 'ONS_INNER']\n```\n:::\n:::\n\n\n::::\n\n### Tidy Up\n\n::: {#552f02f7 .cell execution_count=29}\n``` {.python .cell-code}\ngdf_la.drop(columns=['index_right','HECTARES','NONLD_AREA','ONS_INNER'], inplace=True)\n```\n:::\n\n\nYou'll need to look closely to check that the `value_counts` output squares with your expectations. If you don't get `33` then there's an issue:\n\n::: {#d69bd1d8 .cell execution_count=30}\n``` {.python .cell-code}\nif len(gdf_la.NAME.unique()) == 33:\n    print(\"All good...\")\nelse:\n    print(\"Need to run the next section of code...\")\n    print(f\"Now there are... {len(gdf_la.NAME.unique())} boroughs?\")\n    gdf_la.NAME.value_counts(dropna=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAll good...\n```\n:::\n:::\n\n\n### Find Problematic Listings\n\nIf you were told that you need to run the next sectin of code then see if you can work out what happened...\n\n```python\ntry:\n    print(gdf_la[gdf_la.NAME.isna()].sample(2)[['name', 'NAME']])\n    ax = gdf_la[gdf_la.NAME.isna()].plot(figsize=(9,6), markersize=5, alpha=0.5)\n    boros.plot(ax=ax, edgecolor='r', facecolor='None', alpha=0.5);\nexcept ValueError as e:\n   pass\n```\n\nIn short: in some cases there may be records that fall outside of London because of Airbnb's shuffling approach:\n\n::: {#7af8e8d6 .cell execution_count=31}\n``` {.python .cell-code}\ngdf_la.drop(index=gdf_la[gdf_la.NAME.isna()].index, axis=1, inplace=True)\nprint(f\"Data frame is {gdf_la.shape[0]:,} x {gdf_la.shape[1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData frame is 85,134 x 33\n```\n:::\n:::\n\n\nYou should now have `{python} f\"{gdf_la.shape[0]:,}\" ` records.\n\n### Check\n\n::: {#1e60392c .cell execution_count=32}\n``` {.python .cell-code}\nax = gdf_la.plot(column='NAME', markersize=0.5, alpha=0.5, figsize=(9,7))\nboros.plot(ax=ax, edgecolor='r', facecolor='None', alpha=0.5);\n```\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-33-output-1.png){width=749 height=559}\n:::\n:::\n\n\n### Save\n\n::: {#f04bcf8d .cell execution_count=33}\n``` {.python .cell-code}\ngdf_la.to_parquet(os.path.join('data','geo','Listings_with_LA.geoparquet'))\n```\n:::\n\n\n:::: {.qna}\n\n#### Question\n\n- Do you understand the difference between `how='inner'` and `how='left'`? \n\n> \n\n#### Answer\n\n- Do you understand the difference between `how='inner'` and `how='left'`?\n\n> Left joins preserve *all* records on the left table *regardless* of whether they match something in the right table. In this case, because it's a *spatial* join we keep the listings *regardless* of whether they fall within the London boroughs. Inner joins preserve *only* the records that match between left and right, so in this case if you did a spatial inner join you'd only get the records that fall within a London borough. Right joins do about what you'd expect (not very helpful in this example). Outer joins preserve everything in both tables which, in a spatial context, would probably be a little hard to interpret.\n\n::::\n\n## Create LA Data\n\n### Select LA\n\nSelect a LA that is relevant to _you_ to explore further...\n\n::: {#5ada9eca .cell execution_count=34}\n``` {.python .cell-code}\nLA = 'Waltham Forest'\n```\n:::\n\n\n### Spatial Join\n\nThe first thing we want to do is join MSOA identifiers to each listing. In both cases we want to constrain the data to only be for 'our' LA of interest: \n\n::: {#40d082e6 .cell execution_count=35}\n``` {.python .cell-code}\nmsoadf  = gpd.sjoin(\n            gdf_la[gdf_la.NAME==LA].reset_index(), \n            msoas[msoas.Borough==LA], predicate='within')\n```\n:::\n\n\n### Aggregate\n\nNow aggregate the data by MSOA, deriving median price and a count of the listings:\n\n::: {#f3b30251 .cell execution_count=36}\n``` {.python .cell-code}\nmsoagrdf = msoadf.groupby('msoa11nm').agg({'price':['median','count']}).reset_index()\n```\n:::\n\n\n::: {#1f38dc84 .cell execution_count=37}\n``` {.python .cell-code}\nmsoagrdf.sample(3, random_state=42)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>msoa11nm</th>\n      <th colspan=\"2\" halign=\"left\">price</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>median</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>Waltham Forest 010</td>\n      <td>60.0</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Waltham Forest 026</td>\n      <td>69.5</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Waltham Forest 009</td>\n      <td>64.0</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYou should get something like the below (if you're using Waltham Forest):\n\n::: {#573846d7 .cell execution_count=38}\n\n::: {.cell-output .cell-output-display execution_count=38}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>msoa11nm</th>\n      <th colspan=\"2\" halign=\"left\">price</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>median</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>Waltham Forest 010</td>\n      <td>60.0</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Waltham Forest 026</td>\n      <td>69.5</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Waltham Forest 009</td>\n      <td>64.0</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Resolve Columns\n\nWhich level value is easier to use? 0? or 1?\n\n::: {#a69227d6 .cell execution_count=39}\n``` {.python .cell-code}\nmsoagrdf.columns = msoagrdf.columns.get_level_values(1)\nmsoagrdf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>median</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Waltham Forest 001</td>\n      <td>97.0</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Waltham Forest 002</td>\n      <td>58.0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Waltham Forest 003</td>\n      <td>89.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Waltham Forest 004</td>\n      <td>43.5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Waltham Forest 005</td>\n      <td>50.0</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nFix the missing column name:\n\n::: {#64104f68 .cell execution_count=40}\n``` {.python .cell-code}\nmsoagrdf.rename(columns={'':'msoa11nm', 'count':'listings'}, inplace=True)\nmsoagrdf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>msoa11nm</th>\n      <th>median</th>\n      <th>listings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Waltham Forest 001</td>\n      <td>97.0</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Waltham Forest 002</td>\n      <td>58.0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Waltham Forest 003</td>\n      <td>89.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Waltham Forest 004</td>\n      <td>43.5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Waltham Forest 005</td>\n      <td>50.0</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Join (Again)\n\nHere we see the **difference between merge and join**. You'll notice that `join` operates by taking one data frame as the implicit '*left*' table (the one which *calls* join) while the one that is passed to the join function is, implicitly, the '*right*' table. Join operates only using indexes, so you'll need to insert the code to specify the same index on both data frames, but this can be done **on-the-fly** as part of the joining operation:\n\n::: {#44e8169d .cell execution_count=41}\n``` {.python .cell-code}\nmsoa_gdf = msoagrdf.set_index('msoa11nm').join(\n                msoas[msoas.Borough==LA].set_index('msoa11nm'), \n                rsuffix='_r')\nmsoa_gdf.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median</th>\n      <th>listings</th>\n      <th>OBJECTID</th>\n      <th>BNG_E</th>\n      <th>BNG_N</th>\n      <th>geometry</th>\n      <th>Borough</th>\n      <th>msoa11cd</th>\n      <th>msoa11hclnm</th>\n      <th>Subregion</th>\n    </tr>\n    <tr>\n      <th>msoa11nm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Waltham Forest 001</th>\n      <td>97.0</td>\n      <td>17</td>\n      <td>863</td>\n      <td>537936</td>\n      <td>194880</td>\n      <td>POLYGON ((537919.442 195742.428, 538051.250 19...</td>\n      <td>Waltham Forest</td>\n      <td>E02000895</td>\n      <td>Chingford Green West</td>\n      <td>Outer East and North East</td>\n    </tr>\n    <tr>\n      <th>Waltham Forest 002</th>\n      <td>58.0</td>\n      <td>14</td>\n      <td>864</td>\n      <td>539350</td>\n      <td>194516</td>\n      <td>POLYGON ((539172.688 195540.000, 539696.813 19...</td>\n      <td>Waltham Forest</td>\n      <td>E02000896</td>\n      <td>Chingford Green East</td>\n      <td>Outer East and North East</td>\n    </tr>\n    <tr>\n      <th>Waltham Forest 003</th>\n      <td>89.0</td>\n      <td>7</td>\n      <td>865</td>\n      <td>539355</td>\n      <td>193522</td>\n      <td>POLYGON ((538862.624 194017.438, 539001.125 19...</td>\n      <td>Waltham Forest</td>\n      <td>E02000897</td>\n      <td>Friday Hill</td>\n      <td>Outer East and North East</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Resolve Geodata\n\nYou need to add a command in order to help python recognise that this should be a GeoDataFrame:\n\n::: {#cef2ad1b .cell execution_count=42}\n``` {.python .cell-code}\nmsoa_gdf = msoa_gdf.set_geometry('geometry')\n```\n:::\n\n\n```python\nmsoa_gdf.plot(column='median', legend=True, figsize=(8,8));\n```\n\nYou should get something like:\n\n::: {#ec665d31 .cell execution_count=43}\n\n::: {.cell-output .cell-output-display}\n![](Practical-08-Selecting_Data_files/figure-html/cell-44-output-1.png){width=500 height=633}\n:::\n:::\n\n\n### Save\n\nJust so that we can pick up here without having to re-run all the preceding cells.\n\n::: {#046f7eed .cell execution_count=44}\n``` {.python .cell-code}\nmsoa_gdf.to_parquet(os.path.join('data','geo',f'{LA}-MSOA_data.geoparquet'))\n```\n:::\n\n\n:::: {.qna}\n\n### Question\n\n- Do you understand the differences between `pd.merge` and `df.join`? and `gpd.sjoin`?\n\n> \n\n- Do you understand why it may be necessary to `set_geometry` in some cases?\n\n> \n\n#### Answer\n\n- Do you understand the differences between `pd.merge` and `df.join`? and `gpd.sjoin`?\n\n> Obviously one of these three is spatial in nature, but beyond that there is a *lot* of overlap and great deal depends on the logic or the linkage. `join` is relatively limited in functionality but is fairly clear about the relationships: if the indexes don't match it doesn't produce anything. `merge` is actually (functionally, at least) more similar to `sjoin` than `sjoin` is to `join` -- this is slightly confusing but can probably be traced back to Pandas' origins in panel data research whereas Geopandas' is more technically correct in its terminology because of the influence of GIS.\n\n- Do you understand why it may be necessary to `set_geometry` in some cases?\n\n> Joins are DataFrame functionality and so are unaware of GeoDataFrames (so the return type devolves to a DataFrame), whereas merges seem to preserve the child class type and mean that a GeoDataFrame is returned even thought this is *also* a Pandas utility function.\n\n::::\n\n",
    "supporting": [
      "Practical-08-Selecting_Data_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}